{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocesamiento - Aumentar la capacidad de computo\n",
    "\n",
    "Hemos visto muchas tecnicas para aumentar la capacidad de computo de un CPU, pero siempre hay un limite. Para ir aun mas lejos, la unica alternativa es usar muchos CPUs conectados juntos. Para algunas tareas, como graficar una perspectiva o simular escenarios, es sencillo, porque el grado de interaccion entre las distintas sub-tareas a realizar es bajo, y los CPUs trabajan cada uno en un caso con zonas de memorias distintas. Poca interaccion entre tareas -> n CPUs -> n veces mas rapido, pero para sub-tareas con muchaa iteraccion mutua, se debe compartir memoria y el proceso se hace menos optimo y mas complicado.\n",
    "\n",
    "## Escenarios\n",
    "\n",
    "cuando hablamso de sistemas multiprocesaodres tenemos dos esquemas: Shared memory, es el mas comun, todas las cpus tienen una unica memoria y la comparten. En los sistemas de memoria compartida todos acceden a la memoria con el mismo nivel de privilegio. Hay un tema importante que es el sincronismo entre CPUs, si todos tratan de usar la misma posicion de memoria no hay ganancia de velocidad, pero en la media que logremos separacion eso es un beneficio. Por otro lado tenemos los sitemas de shared interconnet que tienen dos tipos de memoria, cada cpu tiene su propia memoria donde trabaja, pero se dispone de una segunda memoria de intercionexion compartida en la cual se hace el intercambio de datos entre una cpu y otra. En que difieren? los primeros son mas dificiles de construir en cuanto a hardware pero la realidad es que son faciles de programar, cada programa asume que tiene todo. Los segundos son mas faciles de construir pero mas dificil para programar. El programador no trabaja en forma transparente de lo que hay abajo sino que tiene que saber para poder modificar su programa. El primero se utiliza mas en notebooks, etc.\n",
    "\n",
    "## UMA\n",
    "\n",
    "Cuando hablamos del primer caso, memoria compartida, todas las cpus ven la totalidad del espacio de memoria. Se puede dividire en dos categorias, 1: UMA, todos ven la memoria en igualdad de condiciones, no hay mayores privilegios. Las que son UMA escencialmente hay tres arquitecturas que se usan, las primeras que son las de las notebooks son las del single bus (un solo bus de direcciones y datos) cada core cuando quiere acceder le habla a un MMU y esa MMU coordina los accesos de los distntos cores para acceder a una unica memoria. Son mas faciles de hacer pero es valido y funcional para no mas de 10 o 20 CPUs, llega un momento que el bus pasa a ser un cuello de botella. Para evitar eso, es que se colocan caches entre cada uno de los CPUs y la memoria para evitar que todos los accesos de la CPU lleguen a la memoria, es necesario tener un protocolo de coherencia de cache. Hay otra alternativa, otro extremo. Que pasa si hacemos una matriz entre cpu y memoria, esto reduce mucho la cantidad de choques. Obviamente esto es a expensas de mucho hardware, estoy poniendo caminos redundantes para todas las memorias, es mas facil porque elimine los caches y los protocolos de coherencia de cache, pero esto crece con el cuadrado de pares de memoria cpu. Hay una solucion de compromiso, red omega, que lo que hace es que cada nodo toma dos entradas y genera dos salidas, de esa forma, si bien es verdad que cada cpu no tiene un camino propio a la memoria, pero es una solucion de compromiso que se usa hoy en dia en las supercomputadoras, la cantidad de nodos necesarias para la interconexion en vez de crecer con el cuadrado de pares de memoria cpu crece con el logaritmo por ende se utilziara menos hardware. La mayor parte de la programacion de estos sistemas implica conocer por abajo como es el sistema.\n",
    "\n",
    "## NUMA\n",
    "\n",
    "Tenemos un espacio de memoria unico, pero ahora cada una de las CPUs tiene una memoria de uso no exclusivo pero con acceso mas rapido que los demas. Es importante para que se mantenga la estructura de memoria compartida es que todas las CPUs ven la totalidad del espacio de memoria. En estos casos se puede o no usar el cache, dependera de la arquitectura en particular y de cual es la diferencia entre velocidad entre la memoria local y la memoria remota. \n",
    "\n",
    "## Shared interconnect\n",
    "\n",
    "No tienen el espacio de memoria compartida en su totalidad. Para que esto funcione tenemos que tener dos condiciones, primero una forma raconablemente rapida para intercambiar los datos entre los distintos bloques, como no vemos la posicion de memoria tengo que utilizar esa interconexion para notificar los nodos. Por otro lado, para estos sistemas es imprescindible que las aplicaciones conozcan el hardware. Lo maximo que pueden hacer los SO es repartir el mensasje en los nodos, una alternatica es utilizar el DMA, esto es un segundo modulo que compite con el procesador a los efectos de acceder a memoria. El DMA es valido en un hardware relativamente pequenio, claramente no podria poner un DMA que saque los datos de un nodo que esta aca para que los mande a otro lugar lejano. Hay SO que trabajan con distribucion de tareas con otras funciones donde dado un mensaje y un destinatario relego en el SO entregarle el mensaje al otro nodo. Otros trabajan con una cola de mensajes entrantes. Hay un formato que se llama RPC. Memoria distribuida.\n",
    "\n",
    "## Sistemas distribuidos\n",
    "\n",
    "Estos siteams estan separados completamente geograficamente uno del otro. Los sitemas distrib no solo se usan para ganar en performance sino que tambien para ganar en confiabilidad. Hay aplicaciones donde circustancias raras son inaceptables. Estos sistemas distrib no comparten ninguna parte de la memoria, tienen sistemas indepenedientes que trabajan por separado y a lo sumo intercambian algun blouqe de informacion. Son nodos que tienen una fucnion especficia. Un ejemplo es un avion, una unidad se encarga de detectar en base a siertos sensores cual es la velocidad y la altitud del avion, esa es una unidad, otra se encarga de encontrar cual es la posicion donde esta, esa es otra unidad. Esa informacion se comparte a traves de mensajes entre las computadoras. Los displays que ven los pilotos es una computadora que toma los datos de las otras computadoras y permite que el piloto vea la informacion. Estas cosas no solamente se usan para aumentar la canitdad de recursos sino que tambien aplicaciones de mucha confiabilidad. Estos casos practicamente no tienen un SO, los sistemas distribuidos son muy dedicados, para una aplciacion y no para otra.\n",
    "\n",
    "Dentro de los sistemas distrib podriamos encuadrad distitnas clasificaicones:\n",
    "\n",
    "Cliente-servidor: tengo distintos servidores que calculan distitnas cosas y clientes que requieren de informacion\n",
    "\n",
    "peer-to-peer: los nodos pueden enviarse mensajes de forma indistinta.\n",
    "\n",
    "middleware: hay un pequenio SO que se encarga de compartir los datos, repartir la informacion.\n",
    "\n",
    "three-tier: comun en la industria de servicios, por ejemplo bancos. Suele estar dividido en tres capas, la interrelacion entre los nodos no es muy importante.\n",
    "\n",
    "N-tier:\n",
    "\n",
    "## Maquinas virtuales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
