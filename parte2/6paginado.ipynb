{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Source Code Pro'; font-size: 24px;\">\n",
    "\n",
    "## Repaso de segmentado\n",
    "\n",
    "El segmentado tenia algunos puntos basicos que tenian que cumplirse si o si. La primer cosa que todo sistema de segmentado tiene que tener es que permite la relocacion dinamica de los programas. Para que realmente sea funcional en el sentido de proteger tambien, tendriamos que agregar el limite y la proteccion ante cambios, no solamente que haya una base y un limite sino que las tareas no puedan cambiar la base y el limite. Pero lo mas importante es base, limite y proteccion para que sea un sistema funcional. Despues hay mejora que permiten optimizar el rendimiento del sistema, como poner un segmento presente o ausente y tambien el bit de access que le permite al SO llevar una especie de estadistica de que cosas se estan usando y que no, cosa de que cuando le falte memoria tenga que elegir no al azar que bajar de una forma pensando en funcion de las necesidades del sistema. Pero en definitiva, con base, limite y proteccion ante cambios podriamos tener un sistema de segmentado funcional. Lo que habiamos visto que era muy costoso, tecnicmanete se puede hacer, pero en la practica no es muy realizable es agrandar un segmeto, mover todo a un lugar mas grande, cambiar la base y cambiar el limite y devolverle el control a la tarea. En la practica mover grandes bloques de memoria y copiarlos para otro lado es algo que pierde mucha performance. La idea es que cuando uno hace un task switch la idea es hacerlo cambiando unos pocos registros, entonces si bien es algo tecicnamente posible, no es algo muy realizable cuando hablamos de segmenentado.\n",
    "\n",
    "En el sistema de segmentado en realdiad los segmentos pueden tener todos tamanios distintos, el problema es que siempre piden, devuelven, piden, devuelven entonces la memoria se puede fragmentar. Ese es el problema de fondo del segmentado. \n",
    "\n",
    "El paginado mejora esa performance, todas las paginas son del mismo tamanio y se pueden crear grupos de paginas en cualquier posicion, al poder hacer esas dos cosas (todo mismo tamanio y union en cualquier orden) te ahorras ese problema de fragmentacion de memoria.\n",
    "\n",
    "## Manejo de memoria\n",
    "\n",
    "### **Introduccion al manejo de memoria**\n",
    "\n",
    "Cuando un SO carga una tarea (o proceso) en memoria, debe determinar donde se ubucara exactamente en la memoria fisica. Para ello, es necesario establecer:\n",
    "\n",
    "- Base: Direccion inicial donde se cargara el segmento de memoria del proceso.\n",
    "\n",
    "- Limite: Tamanio del segmento asignado al proceso.\n",
    "\n",
    "Ademas de leer el ejecutable y conocer los segmentos que contiene, el SO debe llevar un regsitro detallado de que areas de la memoria estan ocupadas y cuales estan libres para evitar conflictos y optimizar el uso de recursos.\n",
    "\n",
    "### **Metodos para registrar el uso de memoria**\n",
    "\n",
    "Existen principalmente dos enfoques para mantener un registro del uso de la memoria.\n",
    "\n",
    "a) Bitmaps\n",
    "\n",
    "Un bitmap es una estructura de datos que utiliza bits individuales para representar bloques de memoria. Cada bit indica si un bloque especifico esta libre (0) u ocupado (1).\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Eficiencia en el uso del espacio: Solo se necesita un bit por bloque de memoria, lo que consume muy poco espacio\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Velocidad de busqueda: Encontrar bloques libres puede ser lento, ya que requiere escanear los bits hasta encontrar un bit libre.\n",
    "\n",
    "b) Listas\n",
    "\n",
    "Las listas pueden ser estructuras enlazadas que contienen informacion sobre bloques de memoria libres u ocupados.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Mejor rendimiento en búsquedas: Existen múltiples algoritmos de búsqueda que permiten encontrar bloques libres de manera más eficiente.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Gestión de memoria: Dependiendo del tipo de lista y del algoritmo utilizado, liberar memoria puede ser más lento.\n",
    "\n",
    "### **Tipos de Listas en Manejo de Memoria**\n",
    "\n",
    "Al implementar listas, hay dos opciones principales:\n",
    "\n",
    "- Lista de Bloques Libres: Contiene todos los bloques de memoria que están actualmente disponibles para asignar a nuevos procesos.\n",
    "\n",
    "- Lista de Bloques Ocupados: Contiene todos los bloques de memoria que están siendo utilizados por procesos activos.\n",
    "\n",
    "Generalmente, se prefiere mantener una lista de bloques libres para facilitar la asignación de memoria.\n",
    "\n",
    "### **Algoritmos de Asignación de Memoria**\n",
    "\n",
    "Cuando se utiliza una lista para gestionar la memoria, es crucial decidir cómo asignar los bloques libres a los procesos. A continuación, se describen los principales algoritmos:\n",
    "\n",
    "a) First Fit (Primer Ajuste)\n",
    "\n",
    "- Descripción: Recorre la lista de bloques libres desde el inicio y asigna el primer bloque que sea lo suficientemente grande para el proceso.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Simple y rápido en la mayoría de los casos.\n",
    "\n",
    "    - Favorece el uso de posiciones de memoria bajas.\n",
    "\n",
    "- Desventajas:\n",
    "Puede fragmentar la memoria al dejar pequeños bloques libres que no se pueden reutilizar fácilmente.\n",
    "\n",
    "b) Next Fit (Siguiente Ajuste)\n",
    "\n",
    "- Descripción: Similar al First Fit, pero comienza la búsqueda desde donde se dejó la última asignación, formando una lista circular.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Distribuye mejor las asignaciones a lo largo de la memoria, evitando la acumulación de bloques libres en un solo lugar.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Puede ser ligeramente más complejo de implementar.\n",
    "\n",
    "    - No garantiza una distribución óptima de la memoria.\n",
    "\n",
    "c) Best Fit (Mejor Ajuste)\n",
    "\n",
    "- Descripción: Recorre toda la lista de bloques libres y asigna el bloque que deja el menor desperdicio posible.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Minimiza el desperdicio de memoria al ajustar de manera más precisa el tamaño del bloque.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Requiere más tiempo de búsqueda, ya que debe examinar todos los bloques.\n",
    "\n",
    "    - Puede provocar una fragmentación externa significativa si muchos bloques pequeños quedan libres.\n",
    "\n",
    "d) Worst Fit (Peor Ajuste)\n",
    "\n",
    "- Descripción: Asigna el bloque más grande disponible que sea suficiente para el proceso.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Evita la creación de muchos bloques pequeños al preferir los más grandes.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - No utiliza la memoria de manera eficiente, ya que puede dejar bloques grandes innecesarios.\n",
    "\n",
    "    - Similar al Best Fit, puede ser costoso en términos de tiempo de búsqueda.\n",
    "\n",
    "e) Quick Fit (Ajuste Rápido)\n",
    "\n",
    "- Descripción: Mantiene múltiples listas de bloques libres categorizados por tamaño. Cada lista contiene bloques de tamaños específicos o rangos de tamaños.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Permite una asignación y liberación de memoria muy rápida, ya que se accede directamente a la lista correspondiente.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Requiere más espacio para mantener múltiples listas.\n",
    "\n",
    "    - Puede ser más complejo de implementar y mantener.\n",
    "\n",
    "### **Comparación y Selección del Algoritmo**\n",
    "\n",
    "No existe un algoritmo de asignación de memoria que sea el mejor en todas las situaciones. La elección depende de varios factores:\n",
    "\n",
    "- Tamaño de los Programas: Programas grandes pueden beneficiarse de algoritmos que minimizan la fragmentación.\n",
    "\n",
    "- Frecuencia de Asignaciones y Liberaciones: Sistemas con alta dinámica de procesos pueden preferir algoritmos más rápidos.\n",
    "\n",
    "- Nivel de Ocupación de la Memoria: En sistemas con memoria muy fragmentada, algoritmos que gestionan mejor el espacio pueden ser preferibles.\n",
    "\n",
    "- Requerimientos de Rendimiento: En sistemas donde el tiempo de asignación es crítico, algoritmos más rápidos como Quick Fit pueden ser más adecuados.\n",
    "\n",
    "Cada sistema operativo adopta una estrategia que considera que equilibra mejor estos factores según sus objetivos y el entorno en el que opera.\n",
    "\n",
    "### Explicacion de dani\n",
    "\n",
    "Para poder decir en que lugar va a cargar cada tarea, donde va a poner la base y el limite de cada segmento, a parte de leer el ejecutable, y que dentro de la imagen del ejecutable estuviera detallado cuantos segmentos habia, el SO tiene que tener algun registro de que es lo que tiene usado. Ahi hay escencialmente dos formas de hacerlo. La primera es utilizar bitmaps, como en el extended del filesystem. Ventaja de los bitmaps es que ocupa muy poco espacio, por cada bloque estamos usando un solo bit. La desventaja es que es lento para buscar. Otra alternativa es usar listas. La ventaja es que hay multiples algoritmos de busqueda que permiten buena performance para buscar. Sin embargo dependiendo de que lista utilices puede ser lento para liberar memoria. Cuando uno habla de hacer listas, aparecen dos opciones, una lista de lugar libre o una lista de lo ocupado. En principio puedo usar varios algoritmos, el tema es como voy a alocar el lugar. Primero la first fit: voy a barrer esa lista con todos los elementos que tenga, cada elemento va a representar un blouqe libre, hasta encontrar el primero que tenga tamanio mayor o igual a lo que busco, osea que lo puedo guardar ahi, esta es una alternativa, se le dara mucho uso a las posiciones de memoria baja y poca a las altas. El next fit es una variante del first, en vez de tener una lista encadenada en donde arranco en la primer posicion de memoria y voy hasta la ultima, mantengo una lista circular. Tambien se barre la lista buscando el primer bloque mayor igual al necesario. Luego el best fit, escencialmente consiste en no encontrar el primer lugar que sea mayor igual al que busco, sino que barrer todos y decir cual es el mas chico en que me entra, que tendria menos desperdicio. En ppio parece una buena alternativa pero tiene resultados bastantes negativos. Entonces me encuentro con una cantiadd de memoria que sumada es importante pero la tengo toda repartida en pedacitos. En worst fit se barre la lista completa buscando al mayor bloque mayor igual al necesario. En el quick fit, se manejan mas de una lista. Ninguna es la mejor, alguna tiene mejor performance en alguna situacion y otros mejor en otra. Dependera de los tamanios de los programas, la frecuencia con las que los programas entran y salen, el grado de ocupacion de la memoria. Y los distintos SO optan por un sistema que consideran que es el mejor.\n",
    "\n",
    "## Memoria virtual\n",
    "\n",
    "### **Introducción a la Memoria Virtual**\n",
    "\n",
    "La Memoria Virtual es una técnica que permite a los sistemas operativos utilizar más memoria de la que físicamente está disponible en el hardware. Esto se logra mediante la combinación de la memoria física (RAM) con el almacenamiento en disco, creando una ilusión de un espacio de direcciones continuo y amplio para cada proceso.\n",
    "\n",
    "**Problemas con la Memoria Física Limitada**\n",
    "\n",
    "En sistemas con múltiples procesos, la suma total de la memoria requerida por todos los segmentos de los procesos puede exceder la memoria física disponible. Esto puede llevar a situaciones donde no hay suficiente memoria para asignar a nuevos procesos o para expandir los segmentos existentes de los procesos en ejecución.\n",
    "\n",
    "**Memory Swapping (Intercambio de Memoria)**\n",
    "\n",
    "Para manejar esta situación, los sistemas operativos implementan el memory swapping, que consiste en mover partes de la memoria que no están en uso activo hacia el disco duro, liberando así espacio en la memoria física para otros procesos o para expandir segmentos que lo requieran. Este proceso no espera a que la memoria física se agote completamente, sino que actúa de manera proactiva para mantener un equilibrio y evitar que la memoria se llene por completo.\n",
    "\n",
    "### **Segmentación vs. Memoria Virtual**\n",
    "\n",
    "**Limitaciones del Sistema de Segmentación**\n",
    "\n",
    "En un sistema de segmentación puro, cada segmento de un proceso debe residir en una parte contigua de la memoria física. Si un segmento necesita crecer más allá del espacio disponible en la memoria física, el sistema no puede proporcionarle la memoria adicional, lo que limita la flexibilidad y la escalabilidad de los procesos.\n",
    "\n",
    "**Introducción a la Memoria Virtual**\n",
    "\n",
    "Para superar estas limitaciones, se introduce el manejo de memoria virtual, que ofrece una abstracción más flexible y eficiente. En este sistema, cada proceso percibe un espacio de direcciones virtual continuo y amplio, que puede ser mucho mayor que la memoria física disponible.\n",
    "\n",
    "### **Conceptos Clave de la Memoria Virtual**\n",
    "\n",
    "**Espacio de Direcciones Virtual**\n",
    "\n",
    "Cada proceso tiene su propio espacio de direcciones virtual, que comienza en la dirección 0 y se extiende hasta un límite máximo determinado por la arquitectura del procesador (por ejemplo, 2^56 direcciones para procesadores modernos). Este espacio se divide en bloques de tamaño fijo llamados páginas.\n",
    "\n",
    "**Paginación**\n",
    "\n",
    "La paginación es la técnica mediante la cual el espacio de direcciones virtual se divide en páginas de tamaño constante (por ejemplo, 4KB en arquitecturas Intel). La memoria física también se divide en bloques del mismo tamaño llamados marcos de página.\n",
    "\n",
    "**Estados de una Página**\n",
    "\n",
    "Cada página en el espacio virtual de un proceso puede estar en uno de los siguientes estados:\n",
    "\n",
    "- No Alocada: La página nunca ha sido solicitada por el proceso.\n",
    "\n",
    "- Alocada y Presente: La página está actualmente almacenada en un marco de página en la memoria física.\n",
    "\n",
    "- Alocada y Ausente: La página ha sido asignada al proceso pero se encuentra almacenada en el disco (swap) y no está presente en la memoria física.\n",
    "\n",
    "### **Implementación de la Paginación**\n",
    "\n",
    "**Tablas de Paginación**\n",
    "\n",
    "Para gestionar la conversión de direcciones virtuales a físicas, se utilizan estructuras de datos llamadas tablas de paginación. Estas tablas contienen información sobre dónde se encuentra cada página del espacio virtual en la memoria física o en el disco.\n",
    "\n",
    "**Traducción de Direcciones**\n",
    "\n",
    "El proceso de traducción de una dirección virtual a una dirección física se realiza en dos pasos:\n",
    "\n",
    "- Segmentación (Opcional en Algunos Sistemas): En arquitecturas como x86, la dirección virtual primero pasa por el sistema de segmentación, que la convierte en una dirección lineal.\n",
    "\n",
    "- Paginación: La dirección lineal se divide en partes que indican la ubicación de la página en la tabla de paginación. Por ejemplo, en sistemas x86 de 32 bits, la dirección se divide en 10 bits para el Directorio de Páginas, 10 bits para la Tabla de Páginas y 12 bits para el Offset dentro de la página.\n",
    "\n",
    "**Registro CR3**\n",
    "\n",
    "En arquitecturas x86, el registro CR3 contiene la dirección física de la tabla de directorio de páginas del proceso actual. Este registro es esencial para que el procesador localice rápidamente las tablas de paginación necesarias para la traducción de direcciones.\n",
    "\n",
    "### **Manejo de la Tabla de Paginación**\n",
    "\n",
    "**TLB (Translation Lookaside Buffer)**\n",
    "\n",
    "Debido a que acceder a las tablas de paginación en memoria puede ser costoso en términos de tiempo, se utiliza un TLB (Translation Lookaside Buffer), que es una caché especial en el procesador. El TLB almacena un número limitado de entradas de paginación recientes para acelerar la traducción de direcciones.\n",
    "\n",
    "- TLB de Nivel 1: Suele tener un número reducido de entradas (por ejemplo, 128 para código y 64 para datos), asumiendo que los programas utilizan repetidamente un conjunto pequeño de páginas.\n",
    "\n",
    "- TLB de Nivel 2: Más grande que el de nivel 1 pero más lento, puede contener más entradas (por ejemplo, 512) y ayuda a mantener una mayor cantidad de traducciones de direcciones.\n",
    "\n",
    "**Manejo de Faltas de Página (Page Faults)**\n",
    "\n",
    "Cuando una página no está presente en el TLB ni en la memoria física, se produce una interrupción de falta de página (page fault). El sistema operativo debe entonces:\n",
    "\n",
    "- Determinar la Causa: Si la página no ha sido alocada, se asigna nueva memoria. Si la página está ausente, se carga desde el disco.\n",
    "\n",
    "- Actualizar las Tablas de Paginación: Se actualiza la tabla de paginación para reflejar la nueva ubicación de la página.\n",
    "\n",
    "- Actualizar el TLB: La nueva traducción de dirección se inserta en el TLB para acelerar futuras traducciones.\n",
    "\n",
    "**Bits de Control en las Entradas de Página**\n",
    "\n",
    "Cada entrada en las tablas de paginación contiene bits de control que indican el estado de la página:\n",
    "\n",
    "- Bit de Presencia: Indica si la página está presente en la memoria física.\n",
    "\n",
    "- Bit de Acceso: Indica si la página ha sido accedida recientemente.\n",
    "\n",
    "- Bit de Modificación: Indica si la página ha sido modificada (solo en sistemas x86).\n",
    "\n",
    "Estos bits ayudan al sistema operativo a gestionar eficientemente la memoria, decidiendo qué páginas mover al disco y cuáles mantener en la memoria física.\n",
    "\n",
    "### **Ventajas de la Memoria Virtual**\n",
    "\n",
    "- Aislamiento de Procesos: Cada proceso tiene su propio espacio de direcciones virtual, lo que mejora la seguridad y estabilidad del sistema.\n",
    "\n",
    "- Eficiencia en el Uso de la Memoria: Permite que solo las páginas utilizadas actualmente estén en la memoria física, optimizando el uso de recursos.\n",
    "\n",
    "- Flexibilidad: Facilita la ejecución de procesos que requieren más memoria de la que físicamente está disponible.\n",
    "\n",
    "- Facilita la Programación: Los programadores pueden diseñar aplicaciones sin preocuparse por las limitaciones de la memoria física.\n",
    "\n",
    "### **Desventajas y Desafíos**\n",
    "\n",
    "- Sobrecarga de Gestión: La traducción de direcciones y el manejo de tablas de paginación pueden añadir una sobrecarga al sistema.\n",
    "\n",
    "- Latencia por Faltas de Página: Acceder al disco para cargar páginas ausentes es mucho más lento que acceder a la memoria física, lo que puede afectar el rendimiento.\n",
    "\n",
    "- Fragmentación Interna: El uso de páginas de tamaño fijo puede llevar a una utilización ineficiente de la memoria en ciertos casos.\n",
    "\n",
    "### **Ejemplo Práctico: Arquitectura x86**\n",
    "\n",
    "En la arquitectura x86, la conversión de direcciones virtuales a físicas se realiza de la siguiente manera:\n",
    "\n",
    "- Dirección Virtual: Se divide en segmentos de código, datos, etc.\n",
    "\n",
    "- Segmentación: La dirección virtual se convierte en una dirección lineal añadiendo la base del segmento y verificando que no exceda el límite.\n",
    "\n",
    "- Paginación:\n",
    "\n",
    "    - La dirección lineal se divide en tres partes: 10 bits para el Directorio de Páginas, 10 bits para la Tabla de Páginas y 12 bits para el Offset.\n",
    "\n",
    "    - El registro CR3 apunta al Directorio de Páginas del proceso actual.\n",
    "\n",
    "    - Usando los 10 bits iniciales, se accede al Directorio de Páginas para obtener la dirección de la Tabla de Páginas.\n",
    "\n",
    "    - Con los siguientes 10 bits, se accede a la Tabla de Páginas para obtener la dirección física del marco de página.\n",
    "\n",
    "    - Finalmente, se añade el Offset para obtener la dirección física completa.\n",
    "\n",
    "### **Optimización y Estrategias de Caché**\n",
    "\n",
    "Para mejorar el rendimiento, se utilizan varias estrategias:\n",
    "\n",
    "- Caching en el TLB: Almacenar las traducciones de direcciones más usadas para reducir el tiempo de acceso.\n",
    "\n",
    "- Algoritmos de Reemplazo de Páginas: Decidir qué páginas mover al disco cuando se necesita liberar espacio en la memoria física (por ejemplo, LRU - Least Recently Used).\n",
    "\n",
    "- Prefetching: Cargar páginas anticipadamente basándose en patrones de acceso para reducir faltas de página.\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La Memoria Virtual es una pieza fundamental en la arquitectura de los sistemas operativos modernos, permitiendo una gestión eficiente y flexible de la memoria. Mediante técnicas como la paginación y el uso de estructuras como el TLB, se logra optimizar el uso de la memoria física, facilitar la ejecución de múltiples procesos y proporcionar a los programadores un espacio de direcciones amplio y continuo. Aunque introduce ciertos desafíos y sobrecargas, las ventajas en términos de aislamiento, flexibilidad y eficiencia hacen que la memoria virtual sea una solución indispensable en la computación actual.\n",
    "\n",
    "### Explicacion de dani\n",
    "\n",
    "La realidad es que si nosotros sumamos toda la memoria que ocupan los segmentos podriamos tener mas lugar asociado a los procesos que la memoria fisica. Ese proceso de ir bajando a disco las cosas que no uso es lo que se conoce como memory swapping, es un proceso que comienza cuando el SO se empieza a quedar sin memoria, mientras que tenga memoria, se la da los procesos y no conviene bajarla a disco. El SO no espera a que haya 0% de memoria libre para bajar a disco, va mirando y hace lugar con anticipacion. El problema del sistema de segmentado es que si un segmento comienza a crecer y crecer y la tarea le pidiera mas memoria que el total del sistema, nunca se la podria dar. No podria haber nunca un segmento mayor que la totalidad de memoria. Por eso aparece el otro sistema de manejo de memoria, que se llama manejo de memoria virtual, es algo independiente en principio del segmentado mas alla de que se pueda usar en conjunto. Consiste en lo siguiente: todos los procesos ven un enorme bloque de ram que empeiza en la cero hasta la cantidad maxima de memoria que se podria alocar, por ej un procesador hoy en dia tienen 56 bits de adress para la memoria, 2^56 daria varios teras, entonces alguien estaria viendo un bloque de varios teras. En ppio para el programador esta buenisimo porque dice que tiene todo lo que necesita. Este enorme bloque esta dividio en paginas, estas paginas con bloques de tamanio constante, en caso de intel son 4k. Entonces ese enorme bloque de RAM es una sucesion de bloquecitos de 4k, uno debajo del otro. Cada uno de esos bloquecitos de 4k tienen un estado, puede estar no alocado, osea el proceso nunca la solicito y el proceso no tiene asociado una pagina. Por otro lado, puede estar alocado y presente, osea que esa pagina dentro del espacio virtual del proceso realmente se corresponde con una pagina fisica que esta en algun lado. Y puede estar alocada y ausente, es decir estaba alocada, en algun momento correspondio a una pagina fisica, pero se la bajo a disco entonces ahora no esta. Este nuevo sistema se llama paginado porque esta basado en estos bloques de memoria de tamanio constatne que se llaman paginas. Ahora apaece un problema nuevo, esto al igual que segmentado se maneja por hardware. En segmetado para no tener que ir a memoria a buscar la tabla de segemtnos cada vez que accediamos a una posicion de memoria, lo que se hacia era al momento de cargar un registro de segmentacion ahi se iba a la tabla y se copia el registro del procesador la bases el limite, etc. Es un registro oculto uno solo ve el numero de segmento. Una vez que cargue el registro de segmentacion ya tengo todo en el procesador. Ahora, por otro lado, estamos hablando de miles y miles de paginas, para cada pagina tendriamos que tener alguna entrada en algun lado. El tema es donde lo metemos, esa tabla es tan grande que no podemos meterla en registro. Como podemos mantener esto en memoria? La respuesta es un cache especial que tiene el procesador que se llama TLB que contiene algunas de las entradas de la pagina. Este sistema de paginado solo es viable por como funcionan los programas hoy, si el dia de maniana hubiera un cambio radical en la forma de programar seria posible que esto no funcione mas. Porque funciona esto? porque la realidad indica que los programas utilizan una poca cantidad de paginas a la vez y las usa muchas veces. Por esa forma en que trabajan los programas es que esto es viable. Un ejemplo: el primero que utilizo este sistema fue MULTICS pero hoy en dia la mayoria de los procesadores lo utilizan. El TLB de nivel 1 tiene para codigo 128 entradas, asume que un programa no utiliza mas de 128 paginas de 4k cada una en el codigo que esta ejecutando. Para los segmentos de datos tiene 64 entradas. Y tambien tiene un nivel 2, mas lento que nivel 1 pero mas rapido que RAM que tiene 512 entradas, asume que cuando el proceso esta ejecutando, entre codigo y dato no supera los 2 megas, 512 entradas de 4k cada una. Claramente es un tema empiricio, los procesadores van variando en el tiempo, entre ellos se pelea el 1 o 2% de velocidad, entonces esto es una foto en el tiempo. Por supuesto si algo no esta en el cache hay que ir a RAM a buscarla, no queda otra hay que ir a RAM, en cuanto voy a RAM voy a tratar de cachearlo para tenerlo para despues. En algun momento se nos decia que cambiar de thread es menos costoso que cambair de proceso, como los threads comparten la memoria, obviamente usan el mismo cache del mismo TLB, si cambio de thread es probable que el contenido del TLB me sirva, cuando cambio de proceso normalmente el proceso de cambiar de un proceso a otro (task switch) se flashea el TLB (se lo borra por completo) para que empiece a aprender las paginas del nuevo proceso. Que hacer cuando una pagina no esta en el cache depende del procesador. La familia del 8086 se le carga cierta info para que el propio procesdor pueda entrar a la tabla de paginas para bajarse lo que le falta. Hubo otros procesadores que requerian del SO, cuando una pagina no estaba el SO era el que tenia que tener la tabla, agarrarlo, cargarlo en un registro, etc.. esa alternativa es mas lenta porque es por software, en el caso de x86 se hace por hardware. Al igual que los segmentos el sistema de paginado tiene un bit de acces por ende el SO puede saber que pagina se esta usando y cual no, y llegado el caso llevar esa estadistica para cuando necesita memoria y no hay poder bajar ciertas paginas. Tambien tiene que tener un bit de present dado que deseamos que el SO pueda bajar paginas a disco y transferirle el control a la tarea y que nos avise el hardware si la van a usar y si no la van a usar que siga ejecutando. Hay un bit mas que en el x86 no lo tiene en el segmentado pero si en el paginado que es el que la pagina fue modificada, toda operacion de escritura sobre la pagina prende ese bit. En el caso de los segmentos que son read only no tiene mucho sentido y el SO ya puede optimizarlos de una. La interrupcion que genera el sistema de paginado cuando el programa quiere acceder a una pagina que no existe, sea que este en disco o sea que no fue alocada, se conoce como page fault. El SO tiene que ver cual de los dos casos es, si es por no ser alocada o porque no esta presente. Paginado en los procesadores x86, lamentablemnte en el x86 no se puede apagar el segmentado, normalmente el paginado es mas eficiente porque tiene mas granularidad y encima como son todas de tamanio fijo no hay que ir buscando donde entre. Normalmente cuando usamos en un programa una direccion, esa direccion es lo que se conoce como direccion virtual, eso no tiene nada que ver con la direccion fisica. En los procesadores x86, primero, la direccion pasa por el sistema de segmentado. Pero primero se convierte esa direccion logica o virtual en lo que se llama direccion lineal, como se hace? se pasa por el sistema de segmentado, es decir se le suma la base y se fija que no supere el limite. Si el paginado esta apagado, la direccion lineal es la direccion fisica. Si el paginado esta encedido, ahora hay una segunda conversion por el sistema de paginado, en el cual la direccion lineal se va a convertir en la direccion fisica pasando por todas las tablas de paginado. Entonces la direccion virtual o logica primero la transofrma el segmentado, genera la direccion lineal, y si esta habilitado esa direccion lineal es transformada por el paginado. Como se convierte la direccion lineal en direccion fisica? habia dos niveles de tablas, el page directory y el page table. Para hacer la conversion de lineal a fisica se parten los 32 bits en 10 + 10 + 12, cada entrada tanto en el page directory como en el page table tienen la estructrua de la imagen de abajo. Entonces, agarro la direccion y la divido en 10, 10, 12. Con los primeros 10, entro en la tabla, como sabe el procesador donde esta esa tabla? hay un registro llamado cr3 que si el paginado esta activado tiene que ser inicializado en la direccion de memoria fisica que contiene el page direcroty. Con estos 10 bits elije una de las 1024 entradas, ahora esa entrada no me da la direccion fisica, me da la direccion de otra entrada en otra tabla. Con los siguientes 10 bits entro en una de las entrada de esa tabla. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
