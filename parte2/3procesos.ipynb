{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Source Code Pro'; font-size: 24px;\">\n",
    "\n",
    "## Procesos\n",
    "\n",
    "A que llamamos proceso? Es como una abstraccion que tiene el SO de una tarea que se esta ejecutando.\n",
    "\n",
    "### Que informacion tiene?\n",
    "\n",
    "Un proceso encapsula varios tipos de informacion escenciales para su correcta ejecucion y gestion por parte del SO. A continuacion, detallamos cada uno de estos componentes:\n",
    "\n",
    "1. El codigo del programa (ejecutable).\n",
    "\n",
    "- Descripcion: Es el conjunto de instrucciones que el procesador ejecuta. Este codigo se carga en la memoria cuando se inicia el proceso.\n",
    "\n",
    "- Ejemplo: Si ejecutas un navegador web, el codigo del navegador es parte del proceso correspondiente.\n",
    "\n",
    "2. Datos que se generaron al programar. \n",
    "\n",
    "- Descripcion: Durante la compilacion de un programa, ademas de generar instrucciones ejecutables, se crean bloques de datos estaticos como variables globales, constantes, y estructuras de datos que el programa utiliza.\n",
    "\n",
    "- Ejemplo: Una aplicacion puede tener una tabla de constantes de configuracion que se define en tiempo de compilacion.\n",
    "\n",
    "3. Datos generados durante la ejecucion del programa. \n",
    "\n",
    "- Descripcion: En la medida que el programa se va ejecutando el programa puede ir pidiendo memoria o ir modificando variables.\n",
    "\n",
    "- Ejemplo: Al abrir un archivo, el programa puede asignar memoria para almacenar el contenido leido.\n",
    "\n",
    "4. Recursos virtuales:\n",
    "\n",
    "- Descripcion: Son entidades que el proceso utiliza para interactuar con el sisteam y otros procesos. Incluyen:\n",
    "    \n",
    "    - Archivos abiertos: Los archivos que el proceso ha abaierto para lectura/escritura.\n",
    "\n",
    "    - Buffers de pantalla: Areas de memoria utilizadas para gestioanr la salida grafica.\n",
    "\n",
    "    - Semaforos y Mutex: Mecanismos de sincronizacion para gestionar el acceso concurrente a recursos compartidos.\n",
    "\n",
    "    - Conexiones de red: Sockets abiertos para comunicacion a traves de la red.\n",
    "\n",
    "- Ejemplo: Un servidor web tiene multiples conexiones de red abiertas para atender a los clientes.\n",
    "\n",
    "5. Informacon de prioridad de ejecucion y tiempo de ejecucion\n",
    "\n",
    "- Descripcion: El SO asigna prioridades a los procesos para determinar el orden en que se ejecutan. Ademas, lleva un seguimiento del tiempo que cada proceso ha estado en ejecucion.\n",
    "\n",
    "- Ejemplo: Un proceso de impresion puede tener una prioridad baja, mientras que un proceso de reproduccion de video puede tener una prioridad mas alta para mantener la fluidez.\n",
    "\n",
    "\n",
    "6. Informacion de seguridad (usuario duenio del proceso). \n",
    "\n",
    "- Descripcion: Cada proceso esta asociado a un usuario que es su duenio, esta informacion es crucial para la gestion de permisos y seguridad.\n",
    "\n",
    "- Funcion:\n",
    "\n",
    "    - Control de Acceso: Cuando el proceso intenta acceder a un recurso (como un archivo o una impresora), el SO verifica si el usuario tiene los permisos necesarios.\n",
    "\n",
    "Ejemplo: Un proceso ejecutado por un usuario estandar no podra acceder a archivos del sistema que requieren privilegios de administrador.\n",
    "\n",
    "7. Estado de los registros (cuando el proceso no esta corriendo):\n",
    "\n",
    "- Descripcipn: Si un proceso esta en espera o ha sido interrumpido, el SO debe guardar el estado actual de sus registros de CPU para reanudarlo posteriormente sin perder informacion.\n",
    "\n",
    "- Ejemplo: Si el proceso esta esperando la entrada del usuario, el estado de sus registros se guarda hasya que se recibe la entrada y el proceso puede continuar.\n",
    "\n",
    "### Tabla de procesos\n",
    "\n",
    "Toda esta informacion sobre los procesos se almacenan en una estructura de datos centralizada llamada tabla de procesos. Esta tabla es esencial para que el SO gestione eficientemente los procesos activos y sus estados. \n",
    "\n",
    "- Estructura de datos: Cada entrada en la tabla representa un proceso y contiene toda la informacion mencioanda anteriormente.\n",
    "\n",
    "- Identificacion unica (PID):\n",
    "    \n",
    "    - PID (Process Identifier): Es un numero unico asignado a cada proceso cuando se crea. Este identificador permite al SO y a los usuarios referirse a procesos especificos.\n",
    "\n",
    "    - Ejemplo: En linux, se pueden ver los PIDs usando comandos como ps o top.\n",
    "\n",
    "- Indice de la tabla:\n",
    "\n",
    "    - Descripcion: El PID puede considerarse como el indice de la tabla de procesos, facilitando el acceso rapido a la informacion de un proceso especifico.\n",
    "\n",
    "- Gestion de estados:\n",
    "\n",
    "    - Estados comunes de un proceso:\n",
    "\n",
    "        - Ejecutando (running): El proceso esta actualmente siendo ejecutado por la CPU.\n",
    "\n",
    "        - Listo (ready): El proceso esta preparado para ejecutarse y espera su turno.\n",
    "\n",
    "        - Bloqueado (blocked): El proceso esta eseprando por algun evento, como la finalizacion de una operacion de entrada/salida.\n",
    "\n",
    "___\n",
    "\n",
    "## Multiprocesamiento\n",
    "\n",
    "El multiprocesamiento se refiere a la utilizacion de multiples unidades de procesamiento (procesadores o nucelos) dentro de una misma computadora para ejecutar tareas simultaneas. Esta capacidad permite mejorar el rendimiento, la eficiencia y la capacidad de respuesta del sistema.\n",
    "\n",
    "**1. Evolucion historica del multiprocesamiento**\n",
    "\n",
    "**a) Era de un solo procesador:** Durante muchas decadas, la mayoria de las computadoras estaban equipadas con un solo procesador. Sin embargo, esto no impedia la ejecucion de multiples procesos. A traves de tecnicas como la multiprogramacion y la conmutacion de contexto, los sistemas operativos podian gestionar la ejecucion de varios procesos en aparente simultaneidad. \n",
    "\n",
    "- Multiprogramacion: Permite que multiples programas residan en la memoria al mismo tiempo, de modo que el procesador siempre tenga un proceso listo para ejecutarse.\n",
    "\n",
    "- Conmutacion de contexto: Es el proceso mediante el cual el sistema operativo guarda el estado de un proceso en ejecucion y carga el estado de otro proceso, permitiendo asi la alternancia entre ellos.\n",
    "\n",
    "**b) Inicio de multiprocesamiento:** A medida que las aplicaciones se volvieron mas complejas y las demandas de procesamiento aumentaro, surgio la necesidad de utilizar multiples procesadores. Sin embargo, la implementacion practica de sistemas multiprocesdor fue un desafio tecnico que se abordo con el tiempo.\n",
    "\n",
    "**2. Multiprocesamiento vs. Multitarea**\n",
    "\n",
    "Es importante distinguir entre multiprocesamiento y multitarea, ya que a menudo se confunden:\n",
    "\n",
    "- Multiprocesmiento: Utiliza multiples procesadores para ejecutar multiples procesos simultanemaente\n",
    "\n",
    "- Multitarea: Se refiere a la capacidad de un solo procesador para gestionar multiples tareas medaiente la alterancia rapida entre ellas (time slicing).\n",
    "\n",
    "**3. Funcionamiento de multiprocesamiento**\n",
    "\n",
    "- Un solo procesador:\n",
    "\n",
    "    - Time slicing: El proceso asigna pequenios intervalos de tiempo (timeslice) a cada proceso.\n",
    "\n",
    "    - Concurrencia virtual: Aunque solo un proceso se ejecuta fisicamente en un momento dado, la alternancia rapida crea la ilusion de ejecucion simultanea.\n",
    "\n",
    "    - Ventaja: Simplicidad en la gestion de recursos.\n",
    "\n",
    "    - Desventaja: Limitacion en el rendimiento cuando multiples procesos requieren mucha CPU.\n",
    "\n",
    "- Multiprocesador:\n",
    "\n",
    "    - Paralelismo real: Varios procesos pueden ejecutarse verdaderamente al mismo tiempo en diferentes procesadores.\n",
    "\n",
    "    - Distribucion de cargas: El sistema operativo puede distribuir los procesos de manera equilibrada entre los procesadores disponibles.\n",
    "\n",
    "    - Ventaja: Aumento significativo en el rendimiento y la capacidad de manejo de tareas simultaneas.\n",
    "\n",
    "    - Desventaja: Mayot complejidad en la gestion de recursos y sincronizacion.\n",
    "\n",
    "**4. Gestion de procesos en sistemas multiprocesador**\n",
    "\n",
    "**a) Planificacion de procesos (scheduling):** El SO debe decidir que procesos se ejecutan en que procesadores y cuando. Existen diverssas estrategias:\n",
    "\n",
    "- Round Robin: Distribuye los timeslices de manera equivatitva entre los procesos.\n",
    "\n",
    "- Prioridad: Asigna prioridad a ciertos procesos para que se ejecuten antes que otros.\n",
    "\n",
    "- Balanceo de carga: Distribuye los procesos de manera que se optimice el uso de todos los procesadores y se minimice el tiempo de respuesta.\n",
    "\n",
    "**b) Sincronizacion y comunicacion:** Cuando multiples procesos se ejecutan en diferentes procesadores, es esencial gestionar el acceso a recursos compartidos para evitar condiciones de carrera y garantizar la coherencia de los datos.\n",
    "\n",
    "- Semagoros y Mutex: Herramientas para controloar el acceso a recursos.\n",
    "\n",
    "- Barreras: Sincronizan multiples procesos hasta que todos alcancen un punto especifico en la ejecucion.\n",
    "\n",
    "- Memoria compartida vs paso de mensajes:\n",
    "\n",
    "    - Memoria compartida: Los procesos acceden a una region comun de memoria.\n",
    "\n",
    "    - Paso de mensajes: Los procesos se comunican enviando y recibiendo mensajes a traves de canales definidos.\n",
    "\n",
    "**c) Coherencia de cache:** En sistemas multiprocesador, cada procesador puede tener su propia cache. Mantener la coherencia de los datos en todas las caches es crucial para asegurar que todos los procesadores trabajen con la infomracion mas actualizada.\n",
    "\n",
    "- Protocolos de coherencia: Aseguran que cualquier cambio en un cache se refleje en las demas.\n",
    "\n",
    "- Desafios:\n",
    "\n",
    "    - Incremento en la latencia de acceso a memoria\n",
    "\n",
    "    - Complejidad adicional en el disenio del hardware y del SO.\n",
    "\n",
    "\n",
    "**5. Ventajas del multiprocesamiento**\n",
    "\n",
    "- Mayor rendimiento: Capacidad de ejecutar multiples procesos simultaneamente, reduciendo el tiempo total de ejecucion.\n",
    "\n",
    "- Mejor utilizacion de recursos: Los procesadores adicionales pueden manejar tareas de E/S mientras otros procesadores ejecutan calculos intensivos.\n",
    "\n",
    "- Escalabildiad: Facil incorporacion de mas procesadores para aumentar la capacidad de procesamiento segun sea necesario.\n",
    "\n",
    "- Fiabilidad y tolerancia a fallos: En sisteamas con redundancia, si un proceador falla, otros pueden asumir sus tareas, aumentando la disponibilidad del sistema.\n",
    "\n",
    "- Paralelismo: Permite la ejecucion paralela de tareas que pueden descomponerse en sub-tareas independientes, mejorando la eficencia.\n",
    "\n",
    "**6. Desafios del multiprocesamiento**\n",
    "\n",
    "- Complejijdad en la gestion de SO: Requiere mecanismos avanzados para la planificacion, sincronizacion y comunicacion entre procesos.\n",
    "\n",
    "- Coherencia de datos: Mantener la coherencia de la memoria compartida y las caches es tecnicamente complejo.\n",
    "\n",
    "- Problemas de sincronizacion: Evitar condiciones de carrera y garantizar el acceso seguro a recursos compartidos puede ser dificil.\n",
    "\n",
    "- Costo y consumo de energia: Sistemas con multiples procesadores son mas costosos y consumen mas energia, lo que puede ser una limitacion en ciertos entornos.\n",
    "\n",
    "- Escalabilidad limitada: A medida que se agregan mas procesadores, la complejidad y los costos incrementan, y no siempre se obtiene una mejora lineal en el rendimiento.\n",
    "\n",
    "## Multiprocesamiento y el tiempo virtual:\n",
    "\n",
    "**Concepto de tiempo virtual:** En un sistema multiprocesador, el tiempo virtual se refiere a la abstraccion del tiempo real que perciben los procesos en ejecucion. Aunque multiples procesadores pueden ejecutar procesos simultaneamente, la gestion del tiempo y la asignacion de recursos aun juega un papel crucila en como los procesos perciben su ejecucion.\n",
    "\n",
    "**Que significa que el tiempo sea virtual?**\n",
    "\n",
    "- Simulacion de paralelismo: Incluso en sistemas con multiples procesadores, el SO puede gestionar el tiempo de ejecucion de los procesos de manera que, desde la perspectiva de cada proceso, el tiempo parece avanzar de forma indepnediente y predecible.\n",
    "\n",
    "- Aislamiento de procesos: Cada proceso opera en su propio \"espacio de tiempo\", sin interferir directamente con los tiempos de ejecucion de otros procesos. Esto permite que cada proceso funcione como si tuviera su propio procesador dedicado, aunque en realidad este compartiendo recursos.\n",
    "\n",
    "**Multiprocesamiento con un solo procesadorr vs multiples procesadores**\n",
    "\n",
    "**1) Un solo procesador**\n",
    "\n",
    "- Time slicing: El unico procesador se divide en intervalos de tiempo (timeslicees) que se ajustan a cada proceso. Cada proceso recibe una pequenia fraccion de tiempo para ejecutarse antes de que el procesador cambie al siguiente proceso.\n",
    "\n",
    "- Concurrencia virtual: Debido a la rapidez con la que el procesador alterna entre procesos, da la ilusion de que todos los procesos se estan ejecutando simultaenamente. En realidad, el procesador esta manejando los procesos de forma secuencial muy rapidamente.\n",
    "\n",
    "- Virtualizacion del tiempo:\n",
    "\n",
    "    - Consistencia en la ejecucion: Cada proceso percibe que tiene un tiempo de ejecucion consistente y casi continuo, aunque en realidad este siendo interrumpido y reanudado periodicamente.\n",
    "\n",
    "    - Impacto en el rendimiento: Si bien la percepcion de tiempo es virtual y eficiente, el tiempo real que cada proceso tiene para ejecutarse en cada timeslice es limitado, lo que puede afectar el rendimiento de tareas que requieren ejecucion continua prolongada.\n",
    "\n",
    "**2) Sistemas con multiples procesadores**\n",
    "\n",
    "- Paralelismo real: Cada procesador puede ejecutar un proceso de manera independiente y simulantea, eliminando la necesidad de alternar entre procesos como en un sistema de un solo procesador.\n",
    "\n",
    "- Reduccion de la necesidad de time slicing: Aunque multiples procesadores permiten la ejecucion simultanea, el SO aun puede utilizar tecnicas de time slicding para optimziar el uso de los procesadores, especialmente cuando hay mas procesos que procesadores disponibles.\n",
    "\n",
    "- Virtualizacion del tiempo en sistemas multiprocesador:\n",
    "\n",
    "    - Distribucion de cargas: Los procesos pueden ser asignados dinamicamente a cualquier procesador disponible, haciendo que cada proceso sienta que tiene acceso exclusivo al procesador cuando realmente esta compartiendo recursos.\n",
    "\n",
    "    - Sincronizacion y coherencia: A pesar de la ejecucion simultanea, el SO asegura que la gestion del tiempo y los recursos sean coherentes y aisaldos para cada proceso, manteniendo la virtualziacion del tiempo.\n",
    "\n",
    "**Ventajas de la virtualizacion del tiempo**\n",
    "\n",
    "Mejora de la Utilización del Procesador:\n",
    "\n",
    "- Sin Multiprocesadores: En sistemas de un solo procesador, la virtualización del tiempo permite que el procesador esté siempre ocupado ejecutando algún proceso, evitando tiempos muertos que ocurrirían si se esperara a que un proceso termine completamente antes de iniciar otro.\n",
    "\n",
    "- Con Multiprocesadores: Aunque hay múltiples procesadores, la virtualización del tiempo sigue siendo útil para equilibrar cargas y gestionar eficientemente los recursos cuando hay más procesos que procesadores.\n",
    "\n",
    "Percepción de Responsividad:\n",
    "\n",
    "- Los usuarios perciben que sus aplicaciones responden de manera rápida y continua, ya que el sistema operativo gestiona eficientemente la alternancia de procesos o la ejecución paralela, manteniendo una experiencia fluida.\n",
    "\n",
    "Aislamiento y Seguridad:\n",
    "\n",
    "- Cada proceso opera en su propio \"reloj virtual\", lo que ayuda a aislar los procesos y mejorar la seguridad, ya que no dependen directamente de la ejecución de otros procesos.\n",
    "\n",
    "Flexibilidad en la Gestión de Recursos:\n",
    "\n",
    "- La virtualización del tiempo permite al sistema operativo asignar dinámicamente recursos según las necesidades cambiantes de los procesos, optimizando el rendimiento global del sistema\n",
    "\n",
    "**Desafíos Asociados al Tiempo Virtual**\n",
    "\n",
    "Sobrecarga de Gestión:\n",
    "\n",
    "- El sistema operativo debe gestionar de manera eficiente la asignación y reanudación de procesos, lo que puede introducir una sobrecarga adicional, especialmente en sistemas con muchos procesos.\n",
    "\n",
    "Latencia en la Respuesta:\n",
    "\n",
    "- En sistemas de un solo procesador, los procesos que requieren tiempos de ejecución largos pueden experimentar latencia debido a la frecuencia de los cambios de contexto.\n",
    "\n",
    "Coherencia y Sincronización:\n",
    "\n",
    "- Mantener la coherencia en sistemas multiprocesador es más complejo, ya que los procesos pueden ejecutarse en paralelo pero deben sincronizarse correctamente para acceder a recursos compartidos.\n",
    "\n",
    "**Implementación de Tiempo Virtual en Sistemas Operativos**\n",
    "\n",
    "a. Planificadores de Procesos Avanzados\n",
    "\n",
    "- Algoritmos de Scheduling: Utilizan algoritmos como Round Robin, Prioridad, o Balanceo de Carga para asignar tiemposlices de manera eficiente.\n",
    "\n",
    "- Afinidad de Procesadores: En sistemas multiprocesador, los planificadores pueden asignar procesos a procesadores específicos para mejorar la eficiencia de caché y reducir la latencia.\n",
    "\n",
    "b. Mecanismos de Conmutación de Contexto\n",
    "\n",
    "- Eficiencia en la Conmutación: Minimizar el tiempo que se tarda en guardar y restaurar el estado de los procesos para maximizar el tiempo efectivo de ejecución.\n",
    "\n",
    "- Optimización de Recursos: Reducir la sobrecarga asociada con la conmutación de contexto mejora la eficiencia global del sistema.\n",
    "\n",
    "c. Virtualización de Recursos\n",
    "\n",
    "- Memoria Virtual: Asegura que cada proceso tenga la percepción de tener acceso a una memoria continua y privada, aunque físicamente esté compartiendo la memoria con otros procesos.\n",
    "\n",
    "- Dispositivos Virtuales: Permite que los procesos interactúen con dispositivos de E/S de manera aislada y segura, manteniendo la virtualización del tiempo en la interacción con el hardware.\n",
    "\n",
    "**Resumen Integrado**\n",
    "\n",
    "El multiprocesamiento no solo se trata de tener múltiples procesadores trabajando en paralelo, sino también de cómo el sistema operativo gestiona y asigna el tiempo de ejecución a los procesos. La virtualización del tiempo es una pieza fundamental que permite a los procesos operar de manera aislada y eficiente, independientemente de si están compartiendo un único procesador a través de time slicing o ejecutándose en paralelo en múltiples procesadores.\n",
    "\n",
    "- Con un Solo Procesador:\n",
    "\n",
    "    - Time Slicing: Permite la concurrencia virtual, haciendo que múltiples procesos parezcan ejecutarse simultáneamente mediante la rápida alternancia.\n",
    "\n",
    "- Con Múltiples Procesadores:\n",
    "\n",
    "    - Paralelismo Real: Permite la ejecución simultánea de múltiples procesos, pero la virtualización del tiempo sigue siendo esencial para la gestión eficiente de recursos y la percepción de independencia de los procesos.\n",
    "\n",
    "En ambos casos, la virtualización del tiempo asegura que los procesos tengan una experiencia de ejecución consistente, aislada y eficiente, optimizando la utilización del hardware disponible y mejorando la responsividad del sistema.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "La virtualización del tiempo es un concepto esencial en el multiprocesamiento, ya que permite que múltiples procesos compartan de manera eficiente los recursos del sistema, ya sea a través de la alternancia rápida en un solo procesador o mediante la ejecución paralela en múltiples procesadores. Esta abstracción no solo mejora la utilización de los recursos del sistema, sino que también proporciona una experiencia más coherente y predecible para los procesos en ejecución.\n",
    "\n",
    "Entender cómo el tiempo se virtualiza en sistemas multiprocesador es clave para diseñar y optimizar sistemas operativos que sean eficientes, responsivos y capaces de manejar múltiples tareas de manera efectiva. Si tienes más preguntas o deseas explorar algún aspecto específico con mayor profundidad, ¡no dudes en decírmelo!\n",
    "\n",
    "___\n",
    "\n",
    "## Vida de un proceso: Creacion\n",
    "\n",
    "La creacion de un proceso es el primer paso en el ciclo de vida de un proceso. Un proceso nace cuando se ejecuta una tarea, ya sea iniciada automaticamente al arrancar el sisteam (como el shell) o por una solicitud explicita de otro proceso.\n",
    "\n",
    "### **1) Creacion de procesos en windows:** En windows, la creacion de procesos se maneja principalmente a traves de la API de windows. Las funciones clave involucradas son CreateProcessAsUser() y SetPriorityClass(). A continuacion, se detalla cada una de estas funciones y su funcionamiento.\n",
    "\n",
    "**CreateProcessAsUser():**\n",
    "\n",
    "- Descripcion: Es una funcion de la API de windows que permite a un proceso crear un nuevo proceso que se ejecuta en el contexto de un usuario especifico. Es especialmente util en escenario donde se necesita lanzar procesos con privilegios distitnos o en nombre de otro usuario.\n",
    "\n",
    "- Proceso de creacion:\n",
    "\n",
    "    - Preparación del Token de Usuario: Antes de llamar a CreateProcessAsUser(), generalmente se obtiene un token de usuario válido mediante funciones como LogonUser() o DuplicateToken().\n",
    "\n",
    "    - Configuración de Parámetros: Se configuran los parámetros necesarios, como la ruta del ejecutable, la línea de comandos y las variables de entorno.\n",
    "\n",
    "    - Llamada a la Función: Se invoca CreateProcessAsUser() con los parámetros configurados.\n",
    "\n",
    "    - Gestión del Nuevo Proceso: Si la llamada es exitosa, lpProcessInformation contendrá handles al nuevo proceso y al hilo principal, además del PID (Process Identifier).\n",
    "\n",
    "**SetPriorityClass():**\n",
    "\n",
    "- Descripcipn: Permite ajustar la prioridad de ejecucion de un proceso, lo que influye en la cantidad de tiempo de CPU que recibe en comparacion con otros procesos.\n",
    "\n",
    "- Efecto: Al establecer una clase de prioridad mas alta, el proceso tendra mayor acceso al tiempo de CPU, mejorando su rendimiento en comparacion con procesos de prioridad mas baja.\n",
    "\n",
    "**Proceso de creacion completo en windows:**\n",
    "\n",
    "- Inicio del proceso: Puede ser desde el inicio del sistema (como servicios) o por accion de un usuario (ejecutar una aplicacion)\n",
    "\n",
    "- Llamada a CreateProcessAsUser(): El proceso padre invoca esta funcion pasando el ejecutable y los parametros necesarios.\n",
    "\n",
    "- Asignacion de recursos: El SO asigna recursos como memoria, handles, y establece el contexto de seguridad.\n",
    "\n",
    "- Ejecucion: El nuevo proceso comienza a ejecutarse de forma independiente, con su propio espacio de direcciones y recursos.\n",
    "\n",
    "- Ajustes adicionales: Opcionalmente, el proceso puede ajustar su prioridad usando SetPriorityClass() u otras funciones.\n",
    "\n",
    "### **2) Creacion de procesos en Linux:** En linux, la creacion de procesos se basa en dos funciones principales: fork() y execve(). Este enfoque ofrece una gran flexibildiad y es fundamental para el modelo de procesos en sistemas unix-like.\n",
    "\n",
    "**fork()**\n",
    "\n",
    "- Descripcin: fork() es una llamada al sisteam que crea un nuevo proceso duplicando el proceso existente (proceso padre). El nuevo proceso creado se conoce como proceso hijo.\n",
    "\n",
    "- Comportamiento:\n",
    "\n",
    "    - Al llamar a fork(), el SO crea una copia exacta del proceso padre.\n",
    "\n",
    "    - Proceso padre: Recibe el PID del hijo recien creado.\n",
    "\n",
    "    - Proceso hijo: Recibe 0 como valor de retorno de fork().\n",
    "\n",
    "    - Ambos procesos continuan ejecutandose desde el punto donde se llamo a fork()\n",
    "\n",
    "- Caracteristicas:\n",
    "\n",
    "    - Espacio de direcciones: Inicialmente, el hijo comparte el mismo espacio de direcciones que el padre, pero con copia bajo demanda (copy-on-write), lo que significa que solo se copia realmnete cuando uno de los procesos modifica una pagina de memoria.\n",
    "\n",
    "    - Variables de entorno: Se copian del proceso padre al hijo.\n",
    "\n",
    "    - Handles y recursos: Los descriptores de archivos abiertos y otros recursos se comparten, aunque pueden ser independientes segun el disenio del programa.\n",
    "\n",
    "**execve()**\n",
    "\n",
    "- Descripcion: execve() reemplaza el espacio de direcciones del proceso actual con un nuevo programa. Es comunmente utilizado despues de fork() para que el proceso hijo ejecute un programa diferente al del padre.\n",
    "\n",
    "- Comportamiento:\n",
    "\n",
    "    - Reemplaza el codigo y los datos del proceso actual con los del ejecutable especificado.\n",
    "\n",
    "    - Si execve() es exitoso, no retorna, el proceso se convierte en el nuevo programa.\n",
    "\n",
    "    - En caso de error, retorna -1 y establece errno.\n",
    "\n",
    "**Proceso de creacion completo en linux**\n",
    "\n",
    "- Inicio del proceso: Puede ser desde el arranque del sistema o por un proceso existente que decide crear un nuevo proceso.\n",
    "\n",
    "- Llamad a fork(): El proceso padre invoca fork(), creando un proceso hijo duplicado.\n",
    "\n",
    "- Distincion entre padre e hijo:\n",
    "\n",
    "    - Proceso padre: Continua ejecutando el codigo despues de fork(), generalmente controlando o esperando al hijo.\n",
    "\n",
    "    - Proceso hijo: Puede ejecutar un programa diferente utilizando execve()\n",
    "\n",
    "- Llamada a execve(): El proceso hijo reemplaza su imagen de proceso con el nuevo programa.\n",
    "\n",
    "- Ejecucion independiente: El proceso hijo ejecuta al nuevo programa de manera independiente del padre.\n",
    "\n",
    "\n",
    "**Consideraciones Adicionales en Linux**\n",
    "\n",
    "- Herencia de Recursos: El proceso hijo hereda ciertos recursos del padre, como descriptores de archivos abiertos, variables de entorno y otros parámetros de configuración.\n",
    "\n",
    "- Independencia Posterior: Después de fork() y execve(), el padre y el hijo son procesos completamente independientes. Cambios en uno no afectan al otro, excepto en recursos compartidos (como archivos abiertos si no se cierran).\n",
    "\n",
    "- Gestión de PID: Cada proceso recibe un identificador único de proceso (PID), que es utilizado para gestionar y referenciar el proceso dentro del sistema.\n",
    "\n",
    "\n",
    "### **3) Creación de Procesos en Android**: Android, siendo una plataforma basada en Linux, hereda muchas de sus características para la gestión de procesos. Sin embargo, proporciona interfaces más simplificadas para desarrolladores a través de su framework y APIs.\n",
    "\n",
    "**a. Funciones Simplificadas en Android**\n",
    "\n",
    "- Lanzamiento de Actividades y Servicios:\n",
    "\n",
    "    - En Android, los desarrolladores no manejan directamente llamadas como fork() o execve(). En su lugar, utilizan componentes como Activities, Services, y Broadcast Receivers que el sistema maneja internamente.\n",
    "\n",
    "    - Intent: Un objeto Intent se utiliza para iniciar nuevas actividades o servicios, lo que internamente crea nuevos procesos o utiliza procesos existentes según las necesidades.\n",
    "\n",
    "**b. Manejo de Procesos en Android**\n",
    "\n",
    "- Isolación de Aplicaciones:\n",
    "\n",
    "    - Cada aplicación en Android generalmente se ejecuta en su propio proceso para garantizar la seguridad y estabilidad. Esto evita que una aplicación interfiera directamente con otra.\n",
    "\n",
    "- Gestión de Recursos:\n",
    "\n",
    "    - Android utiliza el Android Runtime (ART) o Dalvik (en versiones anteriores) para gestionar la ejecución de aplicaciones, optimizando el uso de memoria y recursos.\n",
    "\n",
    "- Simplificación para Desarrolladores:\n",
    "\n",
    "    - A diferencia de Linux, donde los desarrolladores pueden necesitar manejar procesos de bajo nivel, Android abstrae gran parte de esta complejidad, permitiendo que los desarrolladores se enfoquen en la lógica de la aplicación.\n",
    "\n",
    "**5. Independencia de Procesos**\n",
    "\n",
    "Es crucial entender que cada proceso creado es una entidad totalmente independiente dentro del sistema operativo. Esto significa que:\n",
    "\n",
    "- Espacio de Memoria Separado: Cada proceso tiene su propio espacio de direcciones de memoria. Los cambios en las variables de un proceso no afectan directamente a otros procesos.\n",
    "\n",
    "- Gestión de Recursos: Aunque algunos recursos pueden ser heredados (como descriptores de archivos), la gestión de estos es independiente, permitiendo que cada proceso administre sus propios recursos sin interferencias.\n",
    "\n",
    "- Seguridad y Estabilidad: La independencia asegura que si un proceso falla, no afecta directamente a otros procesos, mejorando la estabilidad del sistema.\n",
    "\n",
    "**a. Ejemplo de Independencia:**\n",
    "\n",
    "Supongamos que un proceso padre crea un proceso hijo mediante fork() en Linux. Después de la creación:\n",
    "\n",
    "- Proceso Padre: Puede continuar ejecutando su lógica, leyendo o escribiendo en sus propias variables.\n",
    "\n",
    "- Proceso Hijo: Ejecuta un programa diferente mediante execve(), modificando sus propias variables y estado sin impactar al padre.\n",
    "\n",
    "Cualquier cambio realizado en el espacio de memoria del padre no se refleja en el hijo, y viceversa.\n",
    "\n",
    "**6. Proceso de Creación en Detalle**\n",
    "\n",
    "Vamos a detallar el proceso de creación de un proceso en Linux para ilustrar cómo funciona:\n",
    "\n",
    "Invocación de fork():\n",
    "\n",
    "- El proceso actual (padre) llama a fork().\n",
    "\n",
    "- El sistema operativo crea una copia del proceso padre, creando el proceso hijo.\n",
    "\n",
    "- Ambos procesos (padre e hijo) continúan ejecutándose a partir del punto donde se llamó a fork().\n",
    "\n",
    "Diferenciación entre Padre e Hijo:\n",
    "\n",
    "- Padre: fork() retorna el PID del hijo.\n",
    "\n",
    "- Hijo: fork() retorna 0.\n",
    "\n",
    "Ejecución Independiente:\n",
    "\n",
    "- El proceso padre puede continuar realizando tareas, como esperar a que el hijo termine (wait()).\n",
    "\n",
    "- El proceso hijo puede realizar nuevas acciones, como ejecutar un nuevo programa con execve().\n",
    "\n",
    "Reemplazo del Proceso Hijo:\n",
    "\n",
    "- Al llamar a execve(), el proceso hijo reemplaza su código y datos con los del nuevo programa.\n",
    "\n",
    "- El proceso hijo ahora ejecuta un programa completamente diferente, funcionando de manera independiente del padre.\n",
    "\n",
    "Terminación de Procesos:\n",
    "\n",
    "- Ambos procesos, padre e hijo, pueden terminar de forma independiente.\n",
    "\n",
    "- El padre puede recoger el estado de terminación del hijo mediante wait(), evitando procesos huérfanos.\n",
    "\n",
    "___\n",
    "\n",
    "## Vida de un proceso: Terminacion\n",
    "\n",
    "La terminacion de un proceso marca el final de us ciclo de vida en el SO. Un proceso puede finalizar su ejecucion de diversas maneras, cada una con sus propias causas y procedimientos. A continuacion, dertallamos las principales formas en que un proceso puede terminar y como el SO gestiona cada escenario.\n",
    "\n",
    "### **1) Terminacion voluntaria del proceso:** Un proceso puede decidir terminar su ejecucion de manera voluntaria cuando ha completado su tarea o cuando ejecuta una condicion que le impide continuar. Este tipo de terminacion generalmente implica que el proceso devuelva un codigo de retorno al SO, indicando el resultado de su ejecucion.\n",
    "\n",
    "**Codigo de retorno:**\n",
    "\n",
    "- Descripcion: Al finalizar, un proceso suele devolver un codigo de retorno al SO. Este codigo puede ser utilziado por otros procesos (como el proceso padre) para detemrinar el resultado de la ejecucion.\n",
    "\n",
    "- Convencion comun:\n",
    "\n",
    "    - Codigo 0: Indica que el proceso termino correctamente sin errores.\n",
    "\n",
    "    - Codigos negativos o positivos (distintos de 0): Senialan que ocurrieron errores o condiciones excepcionales durante la ejecucion.\n",
    "\n",
    "\n",
    "**Llamadas al Sistema para Terminación**\n",
    "\n",
    "- exit(): En muchos lenguajes de programación, exit() es una función que finaliza la ejecución del proceso actual.\n",
    "\n",
    "- _exit(): Similar a exit(), pero sin realizar ciertas limpiezas como el flushing de buffers estándar. Se utiliza en contextos específicos, como después de una llamada a fork() en Unix/Linux.\n",
    "\n",
    "**Limpieza de Recursos**\n",
    "\n",
    "Antes de finalizar, el proceso realiza una limpieza de los recursos que ha utilizado:\n",
    "\n",
    "- Cierre de Descriptores de Archivos: Se cierran archivos abiertos para liberar descriptores.\n",
    "\n",
    "- Liberación de Memoria Dinámica: Se liberan bloques de memoria asignados dinámicamente para evitar fugas de memoria.\n",
    "\n",
    "- Finalización de Hilos: Si el proceso tiene múltiples hilos, se aseguran de que todos finalicen correctamente.\n",
    "\n",
    "### **2) Terminacion por parte del SO:** El SO puede decidir terminar un proceso por diversas razones, generalmente relacioandas con la seguridad, estabilidad o cumplimiento de politicas del sistema.\n",
    "\n",
    "**Violaciones de permisos**\n",
    "\n",
    "- Descripcion: Si un proceso intenta realizar una operacion para la cual no tiene permisos (por ejemplo acceder a archivos restringidos), el SO puede forzar su terminacion.\n",
    "\n",
    "- Ejemplo: Un proceso de usuario intenta acceder a archivos del sistema protegidos; el SO interrumpe la operacion y termina el proceso para mantener al seguridad.\n",
    "\n",
    "**Errores y fallos criticos**\n",
    "\n",
    "- Descripcion: Cuando un proceso encuentra un error critico o una condicion de fallo, el SO puede cerrar el proceso apra evitar comportamientos indeseados que puedan afectar al sistema.\n",
    "\n",
    "- Manejo de excepciones: En sistemas como windows, las excepciones no manejadas pueden ser captuaradas por el SO, que decide si termina el proceso o permite algun otro tipo de manejo.\n",
    "\n",
    "- Generación de Core Dumps: En algunos sistemas operativos, al finalizar un proceso debido a un fallo, se puede generar un \"core dump\" que contiene el estado de la memoria del proceso en el momento del fallo, útil para depuración.\n",
    "\n",
    "**Violaciones de Integridad del Sistema**\n",
    "\n",
    "- Descripción: Si un proceso intenta modificar componentes críticos del sistema operativo o realizar operaciones que comprometen la integridad del sistema, el SO puede terminar el proceso inmediatamente.\n",
    "\n",
    "- Ejemplo: Un proceso intenta cargar un controlador de dispositivo no autorizado que podría causar inestabilidad en el sistema.\n",
    "\n",
    "**Limitaciones de Recursos**\n",
    "\n",
    "- Descripción: Cuando un proceso excede los límites de recursos asignados (como uso excesivo de CPU, memoria, etc.), el sistema operativo puede decidir terminarlo para mantener la estabilidad del sistema.\n",
    "\n",
    "- Implementación: A través de mecanismos como cgroups en Linux, que permiten limitar y gestionar el uso de recursos por procesos o grupos de procesos.\n",
    "\n",
    "### **3) Terminacion por accion del usuario**: Un usuario puede decidir terminar un proceso manualmente utilizando herramientas proporcionadas por el sistema operativo. Este método es útil para cerrar aplicaciones que no responden o que necesitan ser detenidas por alguna razón.\n",
    "\n",
    "**Herramientas de Gestión de Procesos**\n",
    "\n",
    "- Windows:\n",
    "\n",
    "    - Task Manager (Administrador de Tareas): Permite al usuario ver y finalizar procesos.\n",
    "\n",
    "        - Cómo Usarlo:\n",
    "\n",
    "            1. Presiona Ctrl + Shift + Esc para abrir el Administrador de Tareas.\n",
    "\n",
    "            2. Navega a la pestaña \"Procesos\".\n",
    "\n",
    "            3. Selecciona el proceso que deseas terminar y haz clic en \"Finalizar tarea\".\n",
    "\n",
    "- Linux:\n",
    "\n",
    "    - Comandos kill y killall: Permiten enviar señales a procesos específicos para terminarlos.\n",
    "\n",
    "**Permisos y Seguridad**\n",
    "\n",
    "- Verificación de Permisos:\n",
    "\n",
    "    - El sistema operativo verifica que el usuario que intenta terminar el proceso tenga los permisos necesarios para hacerlo.\n",
    "\n",
    "    - Usuarios Estándar: Pueden terminar procesos que ellos mismos han iniciado.\n",
    "\n",
    "    - Usuarios Administradores/Superusuarios: Pueden terminar cualquier proceso en el sistema.\n",
    "\n",
    "- Proceso sin Permisos Adecuados:\n",
    "\n",
    "    - Si un usuario intenta terminar un proceso para el cual no tiene permisos, el sistema operativo negará la solicitud y, generalmente, mostrará un mensaje de error.\n",
    "\n",
    "**Implicaciones de la Terminación Manual**\n",
    "\n",
    "- Sin Devolución de Código de Resultado:\n",
    "\n",
    "    - En los últimos dos casos mencionados (terminación por el SO o por el usuario), el proceso no devuelve un código de retorno al sistema operativo, ya que la terminación es forzada y no se realiza a través de las rutinas de terminación voluntaria del proceso.\n",
    "\n",
    "- Estado del Proceso:\n",
    "\n",
    "    - El proceso se marca como \"zombie\" temporalmente hasta que el sistema operativo limpia sus recursos y notifica al proceso padre.\n",
    "\n",
    "### **4) Mecanismos de Terminación y Limpieza en el Sistema Operativo**:  Independientemente de cómo se termine un proceso, el sistema operativo realiza una serie de pasos para asegurar que los recursos sean adecuadamente liberados y que el sistema permanezca estable.\n",
    "\n",
    "**Liberación de Recursos**\n",
    "\n",
    "- Memoria: Se libera el espacio de direcciones asignado al proceso.\n",
    "\n",
    "- Descriptores de Archivos: Se cierran todos los descriptores de archivos abiertos por el proceso.\n",
    "\n",
    "- Handles y Otros Recursos: Se liberan handles de objetos del sistema (como semáforos, mutexes, etc.).\n",
    "\n",
    "### **Notificación al Proceso Padre**\n",
    "\n",
    "- Recuperación del Estado de Terminación: El proceso padre puede recoger el estado de terminación del proceso hijo utilizando llamadas como wait() en Unix/Linux o funciones equivalentes en otros sistemas operativos.\n",
    "\n",
    "- Evitar Procesos Huérfanos y Zombies:\n",
    "\n",
    "    - Proceso Huérfano: Un proceso cuya padre ha terminado antes que él. En sistemas Unix/Linux, estos procesos son adoptados por el proceso init.\n",
    "\n",
    "    - Proceso Zombie: Un proceso que ha terminado pero aún no ha sido recogido por su padre. El sistema operativo mantiene su entrada en la tabla de procesos hasta que el padre la recoge.\n",
    "    \n",
    "**Manejo de Señales y Excepciones**\n",
    "\n",
    "- Señales en Unix/Linux: El sistema utiliza señales para manejar eventos como terminaciones forzadas (SIGTERM, SIGKILL) o excepciones.\n",
    "\n",
    "- Excepciones en Windows: Manejo de excepciones no controladas que pueden llevar a la terminación del proceso.\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La terminación de un proceso es una etapa crucial en el ciclo de vida de \n",
    "cualquier aplicación en un sistema operativo. Comprender las diferentes formas en que un proceso puede finalizar, así como los mecanismos que el sistema operativo utiliza para gestionar esta terminación, es fundamental para diseñar aplicaciones robustas, seguras y eficientes.\n",
    "\n",
    "- Terminación Voluntaria: Permite a los procesos finalizar su ejecución de manera ordenada, devolviendo códigos de retorno y liberando recursos adecuadamente.\n",
    "\n",
    "- Terminación por el Sistema Operativo: Asegura la seguridad y estabilidad del sistema al cerrar procesos que violan permisos, presentan errores críticos o consumen excesivos recursos.\n",
    "\n",
    "- Terminación por el Usuario: Proporciona a los usuarios herramientas para gestionar y controlar los procesos en ejecución, permitiendo cerrar aplicaciones que no responden o que necesitan ser detenidas por otras razones.\n",
    "\n",
    "Adoptar buenas prácticas en la terminación de procesos, como manejar adecuadamente los errores, liberar recursos y sincronizar con procesos padres, contribuye a la estabilidad y eficiencia del sistema operativo y de las aplicaciones que se ejecutan en él.\n",
    "\n",
    "___\n",
    "\n",
    "## Vida de un proceso: Estado:\n",
    "\n",
    "Un proceso atraviesa varios estados a lo largo de su ciclo de vida. Estos estados representan la condicion actual del proceso y determinan que acciones puede realizar el SO sobre el. Los principales estados de un proceso incluyen:\n",
    "\n",
    "- New\n",
    "\n",
    "- Ready\n",
    "\n",
    "- Running\n",
    "\n",
    "- Blocked/Waiting\n",
    "\n",
    "- Suspended/Stopped\n",
    "\n",
    "- Zombie\n",
    "\n",
    "- Terminated\n",
    "\n",
    "**Nuevo (New)**\n",
    "\n",
    "- Descripción: Es el estado inicial de un proceso cuando está siendo creado. El sistema operativo está asignando los recursos necesarios, como memoria, identificadores únicos (PID), y configurando las estructuras internas para gestionar el proceso.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - Asignación de espacio en memoria.\n",
    "\n",
    "    - Inicialización de tablas de procesos.\n",
    "\n",
    "    - Configuración de atributos iniciales (prioridad, permisos, etc.).\n",
    "\n",
    "**Listo (Ready)**\n",
    "\n",
    "- Descripción: Un proceso está en estado listo cuando está preparado para ejecutarse y espera a que el sistema operativo le asigne tiempo de CPU. No está esperando por ningún recurso adicional, sino simplemente esperando su turno para ejecutarse.\n",
    "\n",
    "- Características en Diferentes SO:\n",
    "\n",
    "    - Windows: Se denomina \"Ready to Run\".\n",
    "\n",
    "    - Linux: Simplemente \"Ready\".\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - El proceso se encuentra en una cola de procesos listos.\n",
    "\n",
    "    - Espera a ser seleccionado por el planificador de procesos para ejecutarse.\n",
    "\n",
    "**Ejecutando (Running)**\n",
    "\n",
    "- Descripción: El proceso está actualmente siendo ejecutado por la CPU. Solo puede haber tantos procesos en este estado como el número de procesadores o núcleos disponibles en el sistema.\n",
    "\n",
    "- Características en Diferentes SO:\n",
    "\n",
    "    - Windows y Linux: Conceptualmente similares, aunque la implementación puede variar.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - Ejecución de instrucciones del programa.\n",
    "\n",
    "    - Acceso activo a recursos como memoria y dispositivos de E/S.\n",
    "\n",
    "**Bloqueado/Esperando (Blocked/Waiting)**\n",
    "\n",
    "- Descripción: Un proceso entra en este estado cuando no puede continuar su ejecución hasta que ocurra un evento específico, como la finalización de una operación de E/S, la disponibilidad de un recurso, o una señal de sincronización.\n",
    "\n",
    "- Características en Linux:\n",
    "\n",
    "    - Interruptible Sleep (S): El proceso está esperando por un evento y puede ser interrumpido por señales.\n",
    "\n",
    "    - Uninterruptible Sleep (D): El proceso está esperando por un evento que no puede ser interrumpido por señales, típicamente operaciones de E/S críticas.\n",
    "\n",
    "- Características en Windows:\n",
    "\n",
    "    - Waiting: Similar al estado bloqueado en Linux, el proceso espera por eventos como operaciones de E/S o sincronización con otros procesos.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - Liberación de recursos que no son necesarios mientras el proceso está bloqueado.\n",
    "\n",
    "    - Poner el proceso en una lista de espera específica para el evento esperado.\n",
    "\n",
    "**Suspendido/Detenido (Suspended/Stopped)**\n",
    "\n",
    "- Descripción: Un proceso puede ser suspendido o detenido por el usuario o el sistema operativo. En este estado, el proceso no está listo para ejecutarse ni está siendo ejecutado, pero se mantiene en memoria para ser reanudado posteriormente.\n",
    "\n",
    "- Características en Diferentes SO:\n",
    "\n",
    "    - Windows: Los procesos pueden estar en estado \"Suspended\", evitando que se ejecuten hasta que sean reanudados.\n",
    "\n",
    "    - Linux: Similar concepto, aunque no se denomina explícitamente \"suspended\", se maneja mediante señales como SIGSTOP y SIGCONT.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - Pausar la ejecución del proceso.\n",
    "\n",
    "    - Mantener el estado del proceso en memoria para una reanudación rápida\n",
    "\n",
    "**Zombi (Zombie)**\n",
    "\n",
    "- Descripción: Un proceso zombie es un proceso que ha terminado su ejecución (ha llamado a exit()) pero todavía tiene una entrada en la tabla de procesos del sistema operativo. Esto sucede porque el proceso padre aún no ha recogido el estado de terminación del hijo.\n",
    "\n",
    "- Características en Diferentes SO:\n",
    "\n",
    "    - Linux/Unix: Los zombies son comunes en sistemas que utilizan fork() y execve(). El proceso hijo termina, pero el padre no ha llamado a wait() para recoger el estado de terminación.\n",
    "\n",
    "    - Windows: No existe un estado \"zombie\" explícito como en Unix/Linux, pero el sistema maneja la terminación de procesos de manera similar mediante la recolección de su estado de terminación.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - El sistema operativo retiene cierta información del proceso para que el padre pueda recogerla.\n",
    "\n",
    "    - El proceso permanece en estado zombie hasta que el padre lo recoge o el padre termina, en cuyo caso el proceso zombie es adoptado por el proceso init en Unix/Linux.\n",
    "\n",
    "**Terminado (Terminated)**\n",
    "\n",
    "- Descripción: Un proceso entra en el estado terminado cuando ha finalizado su ejecución y todos sus recursos han sido liberados por el sistema operativo. En algunos sistemas, esto puede ser lo mismo que \"zombie\", pero generalmente, un proceso \"terminado\" ya no está en la tabla de procesos y todos sus recursos han sido liberados.\n",
    "\n",
    "- Características en Diferentes SO:\n",
    "\n",
    "    - Windows y Linux: Similar concepto, aunque los detalles de limpieza de recursos pueden variar.\n",
    "\n",
    "- Acciones Comunes:\n",
    "\n",
    "    - Eliminación de la entrada en la tabla de procesos.\n",
    "\n",
    "    - Liberación de memoria y otros recursos.\n",
    "\n",
    "### **Transiciones Entre Estados**\n",
    "\n",
    "Los procesos transitan entre estos estados en respuesta a diferentes eventos y acciones tanto internas (dentro del proceso) como externas (del sistema operativo o el usuario). A continuación, se describen las transiciones más comunes:\n",
    "\n",
    "1. Creación del Proceso\n",
    "\n",
    "- Nuevo → Listo: Cuando el proceso ha sido creado y está listo para ejecutarse.\n",
    "\n",
    "2. Ejecución del Proceso\n",
    "\n",
    "- Listo → Ejecutando: El sistema operativo asigna tiempo de CPU al proceso.\n",
    "\n",
    "- Ejecutando → Bloqueado/Esperando: El proceso realiza una operación que requiere esperar por un evento.\n",
    "\n",
    "- Ejecutando → Terminado: El proceso completa su ejecución voluntariamente o es terminado por el sistema.\n",
    "\n",
    "3. Bloqueo y Espera\n",
    "\n",
    "- Bloqueado/Esperando → Listo: El evento por el cual el proceso estaba esperando ocurre, y el proceso vuelve a estar listo para ejecutarse.\n",
    "\n",
    "4. Suspensión y Reanudación\n",
    "\n",
    "- Listo/Ejecutando → Suspendido/Detenido: El usuario o el sistema operativo suspende el proceso.\n",
    "\n",
    "- Suspendido/Detenido → Listo/Ejecutando: El proceso es reanudado.\n",
    "\n",
    "5. Terminación del Proceso\n",
    "\n",
    "- Ejecutando/Bloqueado/Esperando → Terminado/Zombi: El proceso finaliza su ejecución.\n",
    "\n",
    "- Zombi → Terminado: El proceso padre recoge el estado de terminación, eliminando el proceso zombie.\n",
    "\n",
    "### **Gestión de Estados por el Sistema Operativo**\n",
    "\n",
    "**Planificación (Scheduling):** El planificador del sistema operativo es responsable de decidir qué proceso en estado listo será ejecutado a continuación. Existen diferentes algoritmos de planificación que determinan cómo se asigna el tiempo de CPU:\n",
    "\n",
    "- Round Robin: Cada proceso recibe un timeslice fijo y se rota en la cola de listos.\n",
    "\n",
    "- First-Come, First-Served (FCFS): Los procesos se ejecutan en el orden en que llegaron.\n",
    "\n",
    "- Prioridad: Los procesos con mayor prioridad se ejecutan antes que los de menor prioridad.\n",
    "\n",
    "- Shortest Job Next (SJN): Se ejecutan primero los procesos con la menor duración estimada.\n",
    "\n",
    "**Transiciones Basadas en Eventos:** Las transiciones entre estados están gobernadas por eventos internos y externos, tales como:\n",
    "\n",
    "- Completar una operación de E/S: Transición de bloqueado a listo.\n",
    "\n",
    "- Llegar una señal: Puede interrumpir un proceso en espera y cambiar su estado.\n",
    "\n",
    "- Finalización del tiempo de CPU: Cambio de ejecutando a listo.\n",
    "\n",
    "- Acción del usuario: Suspender o terminar un proceso.\n",
    "\n",
    "**Señales y Notificaciones en Linux:** En Linux, las señales son mecanismos para enviar notificaciones a los procesos, permitiendo que respondan a eventos externos:\n",
    "\n",
    "- SIGTERM: Señal para solicitar una terminación suave del proceso.\n",
    "\n",
    "- SIGKILL: Señal para forzar la terminación inmediata del proceso.\n",
    "\n",
    "- SIGSTOP: Señal para detener (suspender) el proceso.\n",
    "\n",
    "- SIGCONT: Señal para continuar un proceso suspendido.\n",
    "\n",
    "**Mecanismos de Sincronización:** En sistemas multiprocesador, es crucial gestionar cómo los procesos acceden a los recursos compartidos para evitar conflictos y garantizar la coherencia de los datos.\n",
    "\n",
    "- Mutexes y Semáforos: Mecanismos para controlar el acceso a recursos compartidos.\n",
    "\n",
    "- Barreras (Barriers): Permiten sincronizar múltiples procesos hasta que todos alcanzan un punto específico de ejecución.\n",
    "\n",
    "**Implicaciones de los Estados de Proceso**\n",
    "\n",
    "**Uso Eficiente de Recursos:** Al categorizar los procesos en diferentes estados, el sistema operativo puede gestionar los recursos de manera más eficiente, asignando la CPU a los procesos que están listos para ejecutarse y liberando recursos de procesos que están bloqueados o suspendidos.\n",
    "\n",
    "**Estabilidad y Seguridad:** Gestionar adecuadamente los estados de los procesos contribuye a la estabilidad del sistema, evitando que procesos defectuosos consuman recursos excesivos o interfieran con otros procesos. Además, la terminación controlada de procesos que violan permisos o tienen errores críticos protege la seguridad del sistema.\n",
    "\n",
    "**Depuración y Desarrollo:** Comprender los estados de los procesos es fundamental para la depuración y el desarrollo de software, permitiendo identificar cuellos de botella, procesos zombies y problemas de sincronización.\n",
    "\n",
    "___\n",
    "\n",
    "## Threads\n",
    "\n",
    "### **1. Introduccion a los hilos de ejecucion**\n",
    "\n",
    "Hasta ahora hemos discutido los procesos, que son entidades independientes con su propio espacio de memoria y recursos. Sin embargo, manejar multiples tareas dentro de un proceso mediante procesos separados puede ser ineficiente, especialmente cuando las tareas son pequenias o requieren acceso frecuente a recursos compartidos. Aqui es donde entra en juego el concepto de hilos de ejecucion o threads.\n",
    "\n",
    "Un hilo es la unidad mas pequenia de procesamiento que puede ser garantizada de manera independiente por un SO. Los hilos permiten que un proceso realice multiples tareas concurrentemente dentro de un mismo espacio de memoria, aprovechando mejor los recursos del sistema y mejorado la eficiencia y responsividad de las aplicaciones.\n",
    "\n",
    "### **2. Diferencia entre procesos y hilos**\n",
    "\n",
    "| **Característica**       | **Proceso**                                                                                                                                      | **Hilo (Thread)**                                                                                                          |\n",
    "|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Espacio de Memoria**    | Cada proceso tiene su propio espacio de direcciones de memoria, aislado de otros procesos.                                                     | Todos los hilos de un mismo proceso comparten el mismo espacio de direcciones de memoria.                                 |\n",
    "| **Protección**            | Hay una protección estricta entre procesos; un proceso no puede acceder directamente a la memoria de otro.                                     | No hay protección entre hilos de un mismo proceso; cualquier hilo puede acceder y modificar la memoria compartida.        |\n",
    "| **Puntero de Ejecución**  | Cada proceso tiene un único puntero de ejecución.                                                                                              | Cada hilo tiene su propio puntero de ejecución y stack, permitiendo múltiples flujos de control dentro del mismo proceso. |\n",
    "| **Recursos**              | Los procesos son entidades independientes con sus propios recursos (archivos, handles, etc.).                                                  | Los hilos comparten recursos del proceso padre, como descriptores de archivos y memoria.                                  |\n",
    "| **Comunicación**          | La comunicación entre procesos (IPC) es más compleja y costosa.                                                                               | La comunicación entre hilos es más sencilla y rápida, ya que comparten el mismo espacio de memoria.                       |\n",
    "| **Creación y Terminación**| La creación y terminación de procesos es más costosa en términos de recursos y tiempo.                                                        | La creación y terminación de hilos es más ligera y rápida.                                                                |\n",
    "| **Uso Ideal**             | Adecuado para tareas independientes que requieren aislamiento.                                                                                | Ideal para tareas concurrentes que necesitan compartir datos y recursos eficientemente.                                   |\n",
    "\n",
    "### **3. Ventajas de usar hilos**\n",
    "\n",
    "Eficiencia en el uso de recursos:\n",
    "\n",
    "- Menor overhead: Crear y gestionar hilos consume menos recursos que los procesos, ya que comparten el mismo espacio de memoria y recursos del proceso padre.\n",
    "\n",
    "- Mejor utilizacion del CPU: Los hilos permiten que multiples tareas se ejecuten simulatanemante, aprovechando mejor los procesadores multicore.\n",
    "\n",
    "Concurrencia y paralelismo: \n",
    "\n",
    "- Concurrencia: Permite que múltiples hilos realicen tareas aparentemente al mismo tiempo, mejorando la responsividad de las aplicaciones.\n",
    "\n",
    "- Paralelismo: En sistemas con múltiples procesadores o núcleos, los hilos pueden ejecutarse verdaderamente en paralelo, reduciendo el tiempo total de ejecución.\n",
    "\n",
    "Facilidad de comunicacion:\n",
    "\n",
    "- Acceso Compartido a Datos: Los hilos pueden compartir datos fácilmente sin la necesidad de mecanismos complejos de comunicación interprocesos\n",
    "\n",
    "Mejor Diseño de Aplicaciones:\n",
    "\n",
    "- Modularidad: Permite diseñar aplicaciones que realicen múltiples tareas de manera modular y organizada.\n",
    "\n",
    "- Responsividad: En aplicaciones interactivas, como interfaces gráficas, los hilos permiten que la interfaz responda mientras otras tareas se ejecutan en segundo plano.\n",
    "\n",
    "### **4. Gestión de Hilos en el Sistema Operativo**\n",
    "\n",
    "Para manejar múltiples hilos dentro de un proceso, los sistemas operativos han evolucionado para incluir estructuras y mecanismos específicos que facilitan la creación, gestión y sincronización de hilos.\n",
    "\n",
    "Estructuras de Datos: Tabla de Hilos\n",
    "\n",
    "Además de la tabla de procesos (process table), los sistemas operativos mantienen una tabla de hilos (thread table) donde cada hilo tiene su propia entrada que incluye información como:\n",
    "\n",
    "- ID del Hilo (Thread ID): Un identificador único para cada hilo dentro del proceso.\n",
    "\n",
    "- Estado del Hilo: Similar a los estados de los procesos (listo, ejecutando, bloqueado, etc.).\n",
    "\n",
    "- Puntero de Ejecución (Program Counter): Indica la próxima instrucción a ejecutar.\n",
    "\n",
    "- Stack Propio: Cada hilo tiene su propio stack para manejar llamadas de funciones y variables locales.\n",
    "\n",
    "- Registro de CPU: Estado de los registros de CPU para restaurar el contexto del hilo cuando es programado para ejecutarse.\n",
    "\n",
    "Planificación de Hilos\n",
    "\n",
    "El planificador de hilos del sistema operativo decide qué hilo se ejecuta en qué procesador y cuándo. Esto puede incluir:\n",
    "\n",
    "- Aprovechamiento de Multiprocesadores: Distribuir hilos entre múltiples procesadores para maximizar el paralelismo.\n",
    "\n",
    "- Afinidad de Hilos: Asignar hilos a procesadores específicos para mejorar la eficiencia de caché y reducir la latencia.\n",
    "\n",
    "- Equidad y Prioridad: Asegurar que todos los hilos tengan una oportunidad justa de ejecutarse, respetando las prioridades asignadas.\n",
    "\n",
    "### **5. Creación y Terminación de Hilos**\n",
    "\n",
    "Creación de Hilos\n",
    "\n",
    "La creación de hilos generalmente implica las siguientes características:\n",
    "\n",
    "- Puntero de Ejecución y Stack Propio: Cada hilo necesita su propio puntero de ejecución y stack para operar de manera independiente.\n",
    "\n",
    "- Compartición de Datos: Los hilos comparten el espacio de memoria del proceso, permitiendo el acceso a variables globales y estructuras de datos compartidas.\n",
    "\n",
    "- Sincronización: Dado que los hilos comparten recursos, es esencial manejar la sincronización para evitar condiciones de carrera y asegurar la coherencia de los datos.\n",
    "\n",
    "Terminación de Hilos\n",
    "\n",
    "Los hilos pueden terminar de diversas maneras:\n",
    "\n",
    "- Terminación Voluntaria: El hilo puede terminar su ejecución llamando a pthread_exit() o simplemente retornando de la función asignada.\n",
    "\n",
    "- Terminación Forzada: Un hilo puede ser cancelado por otro hilo usando pthread_cancel(), aunque esto debe manejarse con cuidado para evitar inconsistencias.\n",
    "\n",
    "### **6. Sincronización y Seguridad en Hilos**\n",
    "\n",
    "Dado que los hilos comparten el mismo espacio de memoria, es crucial manejar adecuadamente la sincronización para evitar condiciones de carrera y garantizar la coherencia de los datos.\n",
    "\n",
    "Mecanismos de Sincronización\n",
    "\n",
    "1. Mutexes (Mutual Exclusion): Permiten que solo un hilo acceda a una sección crítica del código a la vez.\n",
    "\n",
    "2. Semaforos: Permiten controlar el acceso a un recurso limitado, permitiendo un numero especifico de hilos.\n",
    "\n",
    "3. Condicionales (condition variables): Permiten a los hilos esperar por ciertas condiciones antes de continuar.\n",
    "\n",
    "Evitar condiciones de carrera\n",
    "\n",
    "Una condición de carrera ocurre cuando múltiples hilos acceden y modifican datos compartidos simultáneamente sin una sincronización adecuada, llevando a resultados impredecibles.\n",
    "\n",
    "\n",
    "### **7. Impacto en la Gestión del Sistema Operativo**\n",
    "\n",
    "Con la introducción de hilos, la gestión del sistema operativo ha evolucionado para manejar no solo procesos, sino también múltiples hilos dentro de cada proceso. Esto requiere:\n",
    "\n",
    "- Extensión de la Tabla de Procesos: Ahora se mantiene una tabla de hilos adicional para gestionar los hilos de cada proceso.\n",
    "\n",
    "- Planificación Avanzada: El planificador debe gestionar tanto procesos como hilos, asignando recursos de CPU de manera eficiente.\n",
    "\n",
    "- Sincronización de Recursos: Implementación de mecanismos para garantizar que los hilos compartidos no causen inconsistencias en el sistema.\n",
    "\n",
    "### **8. Consideraciones de Diseño al Usar Hilos**\n",
    "\n",
    "1. Sincronización Adecuada:\n",
    "\n",
    "- Evitar condiciones de carrera y asegurar la coherencia de los datos compartidos mediante mecanismos de sincronización como mutexes, semáforos y variables condicionales.\n",
    "\n",
    "2. Evitar Deadlocks:\n",
    "\n",
    "- Diseñar la adquisición de recursos de manera ordenada y evitar ciclos de dependencia entre hilos para prevenir bloqueos mutuos.\n",
    "\n",
    "3. Manejo de Errores:\n",
    "\n",
    "- Implementar manejadores de errores robustos dentro de los hilos para asegurar que fallos en un hilo no afecten negativamente a otros.\n",
    "\n",
    "4. Optimización del Uso de Hilos:\n",
    "\n",
    "- No crear más hilos de los necesarios para evitar la sobrecarga del sistema.\n",
    "\n",
    "- Utilizar pools de hilos (thread pools) para reutilizar hilos existentes y mejorar la eficiencia.\n",
    "\n",
    "5. Seguridad:\n",
    "\n",
    "- Asegurar que los hilos no realicen operaciones no autorizadas o que comprometan la integridad del proceso.\n",
    "\n",
    "### **9. Impacto en el Sistema Operativo**\n",
    "\n",
    "La introducción de hilos en los sistemas operativos ha permitido una gestión más eficiente y flexible de las tareas concurrentes. Sin embargo, también ha introducido desafíos adicionales:\n",
    "\n",
    "- Complejidad en la Planificación: El planificador debe gestionar múltiples hilos por proceso, optimizando la asignación de recursos y evitando conflictos.\n",
    "\n",
    "- Sincronización y Coherencia: Garantizar que los hilos accedan de manera segura a los recursos compartidos sin causar inconsistencias.\n",
    "\n",
    "- Gestión de Recursos Compartidos: Implementar mecanismos que permitan a los hilos compartir recursos de manera eficiente sin comprometer la seguridad o la estabilidad del sistema.\n",
    "\n",
    "### **10. Conclusión**\n",
    "\n",
    "Los hilos de ejecución son una herramienta poderosa para mejorar la eficiencia y responsividad de las aplicaciones al permitir la realización concurrente de múltiples tareas dentro de un mismo proceso. Al compartir el mismo espacio de memoria y recursos, los hilos facilitan la comunicación y el intercambio de datos, pero también requieren una gestión cuidadosa para evitar problemas de sincronización y condiciones de carrera.\n",
    "\n",
    "Los sistemas operativos modernos están diseñados para soportar múltiples hilos de manera eficiente, proporcionando las estructuras de datos y mecanismos necesarios para su gestión y sincronización. Al aprovechar los hilos, los desarrolladores pueden diseñar aplicaciones más robustas y rápidas, optimizando el uso de los recursos del sistema y mejorando la experiencia del usuario.\n",
    "\n",
    "__\n",
    "\n",
    "## Context Switching\n",
    "\n",
    "### **Que es el cambio de contexto?**\n",
    "\n",
    "El cambio de contexto es el proceso mediante el cual el sistema operativo alterna la ejecución de un proceso o hilo por otro. Este mecanismo es esencial para permitir la multiprogramación y la multitarea, ya que permite que múltiples procesos o hilos compartan los recursos de la CPU de manera eficiente.\n",
    "\n",
    "### **Como funciona el cambio de contexto?**\n",
    "\n",
    "Cuando la CPU está ejecutando un proceso o hilo y el sistema operativo decide que debe ceder el control a otro, realiza los siguientes pasos básicos:\n",
    "\n",
    "1. Guardar el Contexto Actual:\n",
    "\n",
    "- Registros de CPU: Se guardan todos los registros de la CPU (como el puntero de instrucción, registros generales, etc.) del proceso o hilo actual.\n",
    "\n",
    "- Información de Estado: Se almacena el estado del proceso o hilo (por ejemplo, si está listo, bloqueado, etc.).\n",
    "\n",
    "2. Seleccionar el Próximo Proceso o Hilo:\n",
    "\n",
    "- El planificador del sistema operativo decide cuál será el siguiente proceso o hilo a ejecutar basado en algoritmos de planificación (como Round Robin, Prioridad, etc.).\n",
    "\n",
    "3. Cargar el Nuevo Contexto:\n",
    "\n",
    "- Registros de CPU: Se cargan los registros de la CPU correspondientes al nuevo proceso o hilo seleccionado.\n",
    "\n",
    "- Información de Estado: Se actualiza el estado del proceso o hilo para reflejar que ahora está en ejecución.\n",
    "\n",
    "### **Impacto del Cambio de Contexto**\n",
    "\n",
    "Cada vez que se realiza un cambio de contexto, la CPU debe dedicar tiempo y recursos a este proceso, lo que puede afectar el rendimiento general del sistema. Minimizar estos costos es esencial para mejorar la eficiencia y la responsividad del sistema operativo.\n",
    "\n",
    "### **Costos del Cambio de Contexto entre Procesos vs. Hilos**\n",
    "\n",
    "Cambio de Contexto entre Procesos\n",
    "\n",
    "Cuando se realiza un cambio de contexto entre procesos, el costo asociado es mayor debido a las siguientes razones:\n",
    "\n",
    "1. Espacio de Direcciones Independiente:\n",
    "\n",
    "- Memoria Virtual: Cada proceso tiene su propio espacio de direcciones de memoria. Al cambiar de un proceso a otro, el sistema operativo debe actualizar el Registro de Segmentos y el Page Table, lo que implica cambiar la memoria virtual asignada a la CPU.\n",
    "\n",
    "- TLB (Translation Lookaside Buffer): El TLB, que almacena traducciones de direcciones virtuales a físicas, debe invalidarse o actualizarse para reflejar el nuevo espacio de direcciones del proceso. Esto puede llevar a una pérdida de eficiencia temporal debido a TLB misses (fallos de TLB).\n",
    "\n",
    "2. Caché de CPU:\n",
    "\n",
    "- Cache de Instrucciones y Datos: La caché de la CPU contiene datos e instrucciones específicos del proceso en ejecución. Al cambiar de proceso, la información en la caché puede no ser relevante para el nuevo proceso, lo que obliga a limpiar o recargar la caché, aumentando la latencia.\n",
    "\n",
    "3. Recursos del Sistema Operativo:\n",
    "\n",
    "- Estructuras de Datos: El sistema operativo debe manejar y actualizar las estructuras de datos que gestionan los procesos, como la tabla de procesos.\n",
    "\n",
    "- Permisos y Seguridad: Al cambiar de proceso, el sistema operativo debe verificar y ajustar los permisos y contextos de seguridad, asegurando que el nuevo proceso tenga acceso solo a los recursos permitidos.\n",
    "\n",
    "4. Recuperación y Asignación de Recursos:\n",
    "\n",
    "- Handles y Descriptores de Archivos: Cada proceso puede tener sus propios handles y descriptores de archivos abiertos, que deben ser gestionados y actualizados durante el cambio de contexto.\n",
    "\n",
    "Consecuencia: Debido a estas múltiples tareas, el costo en tiempo del cambio de contexto entre procesos es alto, lo que puede afectar negativamente el rendimiento si ocurre con frecuencia.\n",
    "\n",
    "### **Cambio de Contexto entre Hilos (Threads)**\n",
    "\n",
    "En contraste, cuando se realiza un cambio de contexto entre hilos dentro del mismo proceso, el costo es mucho menor por las siguientes razones:\n",
    "\n",
    "1. Espacio de Direcciones Compartido:\n",
    "\n",
    "- Memoria Compartida: Todos los hilos dentro de un mismo proceso comparten el mismo espacio de direcciones de memoria. Esto significa que no es necesario actualizar la Page Table ni invalidar el TLB, ya que las direcciones virtuales permanecen consistentes.\n",
    "\n",
    "- Caché de CPU: La caché de instrucciones y datos puede permanecer en gran parte relevante, reduciendo la necesidad de limpiar o recargar la caché.\n",
    "\n",
    "2. Recursos Compartidos:\n",
    "\n",
    "- Handles y Descriptores de Archivos: Los hilos comparten los mismos recursos del proceso, por lo que no es necesario reasignar o gestionar nuevos handles y descriptores durante el cambio de contexto.\n",
    "\n",
    "3. Estructuras de Datos Simplificadas:\n",
    "\n",
    "- Tabla de Hilos: Además de la tabla de procesos, existe una tabla de hilos que es más ligera y específica para gestionar los hilos dentro de un proceso. Actualizar esta tabla es menos costoso que gestionar completamente una nueva entrada en la tabla de procesos.\n",
    "\n",
    "4. Sincronización Simplificada:\n",
    "\n",
    "- Mecanismos de Sincronización: Aunque los hilos comparten memoria, la sincronización entre ellos (usando mutexes, semáforos, etc.) está optimizada para minimizar el overhead en el cambio de contexto.\n",
    "\n",
    "Consecuencia: Debido a que hay menos componentes que actualizar y menos recursos que gestionar, el costo en tiempo del cambio de contexto entre hilos es significativamente menor que entre procesos.\n",
    "\n",
    "### **Ejemplo Práctico**\n",
    "\n",
    "Escenario sin Hilos (Solo Procesos)\n",
    "\n",
    "Supongamos que deseas descargar 10 archivos de internet. Si lo haces utilizando procesos separados, cada descarga implicaría:\n",
    "\n",
    "1. Creación de un Proceso Hijo: Cada descarga inicia un nuevo proceso.\n",
    "\n",
    "2. Cambio de Contexto: El sistema operativo alterna entre estos procesos, cada uno con su propio espacio de direcciones.\n",
    "\n",
    "3. Terminación del Proceso: Al finalizar la descarga, el proceso hijo termina y el sistema operativo libera sus recursos.\n",
    "\n",
    "Problema: Cada cambio de contexto entre procesos introduce un alto costo, lo que puede ralentizar significativamente la descarga total de los 10 archivos.\n",
    "\n",
    "Escenario con Hilos\n",
    "\n",
    "En cambio, si utilizas hilos dentro de un único proceso:\n",
    "\n",
    "1. Creación de Hilos: Inicias 10 hilos dentro del mismo proceso, cada uno encargado de descargar un archivo.\n",
    "\n",
    "2. Cambio de Contexto entre Hilos: El sistema operativo alterna rápidamente entre estos hilos sin necesidad de actualizar completamente el espacio de direcciones ni invalidar la caché.\n",
    "\n",
    "3. Terminación de Hilos: Al finalizar cada descarga, el hilo correspondiente termina, pero el proceso principal sigue activo hasta que todos los hilos han finalizado.\n",
    "\n",
    "Ventaja: El costo total de cambio de contexto es mucho menor, permitiendo que las descargas se realicen de manera más eficiente y rápida.\n",
    "\n",
    "___\n",
    "\n",
    "## Prioridades\n",
    "\n",
    "### **1. Concepto de Prioridad**\n",
    "\n",
    "La prioridad en un sistema operativo es un valor asignado a cada proceso o hilo que indica su importancia relativa en comparación con otros procesos. Esta prioridad influye en el orden en que el planificador del SO asigna tiempo de CPU a los procesos y cómo gestiona los recursos del sistema.\n",
    "\n",
    "### **2. Tipos de Prioridades**\n",
    "\n",
    "Las prioridades pueden clasificarse principalmente en dos categorías:\n",
    "\n",
    "1. Prioridades Estáticas:\n",
    "\n",
    "- Definición: Son asignadas de manera fija al crear el proceso y no cambian durante su ejecución.\n",
    "\n",
    "- Características:\n",
    "\n",
    "    - Más simples de implementar.\n",
    "\n",
    "    - Menos flexibles, ya que no se adaptan a las necesidades dinámicas del sistema.\n",
    "\n",
    "- Ejemplo: Un proceso de sistema crítico como el kernel tiene una prioridad alta que no cambia.\n",
    "\n",
    "2. Prioridades Dinámicas:\n",
    "\n",
    "- Definición: Pueden cambiar durante la ejecución del proceso en función de ciertos criterios o eventos.\n",
    "\n",
    "- Características:\n",
    "    \n",
    "    - Más complejas de implementar.\n",
    "\n",
    "    - Permiten una mejor adaptación a las condiciones cambiantes del sistema.\n",
    "\n",
    "- Ejemplo: Un proceso en primer plano que interactúa con el usuario puede aumentar su prioridad temporalmente para mejorar la responsividad.\n",
    "\n",
    "### **3. Asignación de Prioridades**\n",
    "\n",
    "Las prioridades pueden ser asignadas de diversas maneras, dependiendo del sistema operativo y las necesidades específicas:\n",
    "\n",
    "Números Arbitrarios:\n",
    "\n",
    "- Descripción: Asignación de valores numéricos que representan la prioridad relativa de los procesos. Un número mayor puede indicar una prioridad más alta.\n",
    "\n",
    "- Ejemplo: En algunos sistemas, las prioridades pueden oscilar entre 0 y 31, donde 31 es la más alta.\n",
    "\n",
    "Prioridades Basadas en Categorías:\n",
    "\n",
    "- Descripción: Clasificación de procesos en categorías como \"alta\", \"media\" y \"baja\" prioridad.\n",
    "\n",
    "- Ejemplo: En Windows, las prioridades comunes incluyen \"Real-Time\", \"High\", \"Above Normal\", \"Normal\", \"Below Normal\" y \"Idle\".\n",
    "\n",
    "Prioridades Basadas en la Necesidad de Recursos:\n",
    "\n",
    "- Descripción: Asignación de prioridades en función de la necesidad de acceso a recursos críticos.\n",
    "\n",
    "- Ejemplo: Procesos que realizan operaciones críticas de E/S, como la grabación de un DVD, reciben una prioridad más alta para evitar interrupciones que puedan dañar el disco.\n",
    "\n",
    "### **4. Prioridades Dinamicas y Ajustes de prioridad**\n",
    "\n",
    "Las prioridades dinámicas permiten que el sistema operativo ajuste las prioridades de los procesos en tiempo real para optimizar el rendimiento y la eficiencia. Algunos factores que pueden influir en estos ajustes incluyen:\n",
    "\n",
    "Interacción con el Usuario:\n",
    "\n",
    "- Descripción: Los procesos que interactúan directamente con el usuario, como aplicaciones de interfaz gráfica, suelen recibir un aumento temporal de \n",
    "prioridad para mejorar la experiencia del usuario.\n",
    "\n",
    "- Ejemplo: Cuando un usuario está escribiendo en un editor de texto, el proceso del editor puede tener una prioridad más alta para asegurar que las entradas de teclado se procesen rápidamente.\n",
    "\n",
    "Demanda de Recursos:\n",
    "\n",
    "- Descripción: Si un proceso necesita acceder a recursos críticos, el sistema puede aumentar su prioridad para asegurar que obtenga los recursos necesarios sin retrasos.\n",
    "\n",
    "- Ejemplo: Un proceso que está grabando datos en un dispositivo de almacenamiento crítico puede tener su prioridad aumentada para mantener una transmisión de datos constante y sin interrupciones.\n",
    "\n",
    "Prioridad Manual:\n",
    "\n",
    "- Descripción: Los usuarios o administradores del sistema pueden ajustar manualmente las prioridades de los procesos según sus necesidades.\n",
    "\n",
    "- Ejemplo: Un usuario puede aumentar la prioridad de un proceso de compilación para que termine más rápidamente, o reducir la prioridad de un proceso de descarga para que no interfiera con otras tareas.\n",
    "\n",
    "### **5. Ejemplos Prácticos de Gestión de Prioridades**\n",
    "\n",
    "Interacción en Tiempo Real con el Usuario\n",
    "\n",
    "Cuando una aplicación está en primer plano y requiere una respuesta rápida (por ejemplo, un editor de texto o un navegador web), el sistema operativo puede asignarle una prioridad más alta para asegurar que las acciones del usuario se procesen sin demoras. Esto mejora la experiencia del usuario al hacer que la aplicación sea más responsiva.\n",
    "\n",
    "- Proceso en Primer Plano:\n",
    "\n",
    "    - Prioridad Alta: Aumenta temporalmente la prioridad del proceso para asegurar una respuesta rápida.\n",
    "\n",
    "    - Cambios de Prioridad: Si el proceso se mueve a segundo plano, la prioridad se reduce para liberar recursos para otras tareas.\n",
    "\n",
    "Procesos Críticos de Sistema\n",
    "\n",
    "Algunos procesos son fundamentales para el funcionamiento del sistema operativo y no pueden ser interrumpidos sin causar inestabilidad o fallos.\n",
    "\n",
    "- Ejemplo: El proceso del kernel o los controladores de dispositivos suelen tener la más alta prioridad para asegurar que las operaciones críticas del sistema se ejecuten sin retrasos.\n",
    "\n",
    "Acceso a Dispositivos Críticos\n",
    "\n",
    "Procesos que interactúan con dispositivos que requieren una transmisión continua de datos (como la grabación de un DVD) deben tener una prioridad alta para evitar interrupciones que podrían dañar el dispositivo o la integridad de los datos.\n",
    "\n",
    "- Proceso de Grabación de DVD:\n",
    "\n",
    "    - Prioridad Alta: Para mantener una transmisión constante de datos al dispositivo de grabación.\n",
    "\n",
    "    - Prevención de Interrupciones: Evita que otros procesos de menor prioridad interfieran con la transmisión de datos.\n",
    "\n",
    "Ajustes Manuales por el Usuario\n",
    "\n",
    "Los usuarios pueden ajustar las prioridades de los procesos según sus necesidades actuales, optimizando el rendimiento de tareas específicas.\n",
    "\n",
    "- Ejemplo en Windows:\n",
    "\n",
    "    - Task Manager (Administrador de Tareas): Permite al usuario cambiar la prioridad de un proceso (por ejemplo, de \"Normal\" a \"High\" o \"Realtime\").\n",
    "\n",
    "    - Uso:\n",
    "\n",
    "        1. Abrir el Administrador de Tareas (Ctrl + Shift + Esc).\n",
    "\n",
    "        2. Navegar a la pestaña \"Detalles\" o \"Procesos\".\n",
    "\n",
    "        3. Hacer clic derecho sobre el proceso deseado y seleccionar \"Establecer prioridad\".\n",
    "\n",
    "        4. Elegir la prioridad adecuada (por ejemplo, \"High\" para procesos que requieren mayor atención).\n",
    "\n",
    "### **6. Prioridades Dinámicas y Algoritmos de Planificación**\n",
    "\n",
    "Las prioridades dinámicas permiten que el sistema operativo ajuste las prioridades de los procesos en función de factores como el tiempo de espera, el uso de CPU y las interacciones del usuario. Esto se logra mediante algoritmos de planificación avanzados que equilibran la equidad y la eficiencia.\n",
    "\n",
    "Algoritmos de Planificación Basados en Prioridad\n",
    "\n",
    "Planificación por Prioridad Estática:\n",
    "\n",
    "- Los procesos se ejecutan en orden de prioridad fija.\n",
    "\n",
    "- Ventaja: Fácil de implementar.\n",
    "\n",
    "- Desventaja: Puede causar inanición (starvation) para procesos de baja prioridad.\n",
    "\n",
    "Planificación por Prioridad Dinámica:\n",
    "\n",
    "- Las prioridades de los procesos pueden cambiar durante su ejecución.\n",
    "\n",
    "- Ventaja: Mejora la eficiencia y la responsividad adaptándose a las condiciones actuales.\n",
    "\n",
    "- Desventaja: Más compleja de implementar y requiere mecanismos para ajustar las prioridades sin causar problemas de sincronización.\n",
    "\n",
    "Planificación Multinivel por Colas:\n",
    "\n",
    "- Utiliza múltiples colas de prioridad, donde cada cola tiene una prioridad diferente.\n",
    "\n",
    "- Los procesos se mueven entre colas en función de su comportamiento y necesidades.\n",
    "\n",
    "- Ejemplo: Colas separadas para procesos interactivos y en segundo plano.\n",
    "\n",
    "Algoritmos Específicos\n",
    "\n",
    "Round Robin con Prioridades:\n",
    "\n",
    "- Combina el método Round Robin con asignaciones de prioridad.\n",
    "\n",
    "- Los procesos de mayor prioridad reciben tiemposlices más frecuentes o más largos.\n",
    "\n",
    "Shortest Remaining Time First (SRTF):\n",
    "\n",
    "- Los procesos con el menor tiempo restante de ejecución reciben mayor prioridad.\n",
    "\n",
    "- Ventaja: Minimiza el tiempo de espera promedio.\n",
    "\n",
    "- Desventaja: Puede causar inanición para procesos con tiempos de ejecución largos.\n",
    "\n",
    "Completely Fair Scheduler (CFS) en Linux:\n",
    "\n",
    "- Distribuye el tiempo de CPU de manera equitativa entre los procesos.\n",
    "\n",
    "- Utiliza una estructura de árbol balanceado para gestionar los tiempos de ejecución.\n",
    "\n",
    "- Prioridades Dinámicas: Ajusta las prioridades basándose en la demanda y el comportamiento de los procesos.\n",
    "\n",
    "### **7. Impacto de las Prioridades en el Rendimiento del Sistema**\n",
    "\n",
    "La correcta gestión de las prioridades tiene un impacto significativo en el rendimiento y la experiencia del usuario:\n",
    "\n",
    "Mejora de la Responsividad:\n",
    "\n",
    "- Asignar mayor prioridad a procesos interactivos asegura que las aplicaciones respondan rápidamente a las acciones del usuario.\n",
    "\n",
    "Optimización del Uso de Recursos:\n",
    "\n",
    "- Priorizar procesos que requieren acceso a recursos críticos (como dispositivos de E/S) evita cuellos de botella y mejora la eficiencia del \n",
    "sistema.\n",
    "\n",
    "Equilibrio entre Tareas:\n",
    "\n",
    "- Un sistema bien gestionado puede equilibrar la ejecución de múltiples procesos y hilos, asegurando que tanto\n",
    "\n",
    "los procesos críticos como las tareas en segundo plano se ejecuten de manera eficiente sin interferir negativamente entre sí.\n",
    "\n",
    "Prevención de Inanición (Starvation):\n",
    "\n",
    "- Implementar mecanismos para evitar que los procesos de baja prioridad nunca reciban tiempo de CPU, garantizando que todos los procesos tengan una oportunidad justa de ejecutarse.\n",
    "\n",
    "### **8. Desafíos en la Gestión de Prioridades**\n",
    "\n",
    "Asignación Correcta de Prioridades:\n",
    "\n",
    "- Determinar la prioridad adecuada para cada proceso puede ser complejo, ya que depende de múltiples factores como la importancia de la tarea, la necesidad de recursos y las expectativas del usuario.\n",
    "\n",
    "Evitar la Inanición:\n",
    "\n",
    "- Los procesos de baja prioridad pueden quedar indefinidamente bloqueados si hay siempre procesos de mayor prioridad disponibles para ejecutarse.\n",
    "\n",
    "Balance entre Prioridades:\n",
    "\n",
    "- Mantener un equilibrio entre procesos interactivos y en segundo plano para asegurar que el sistema sea responsivo sin sacrificar la eficiencia global.\n",
    "\n",
    "Seguridad y Estabilidad:\n",
    "\n",
    "- Asegurar que los procesos críticos no sean interrumpidos por procesos de baja prioridad y que los ajustes de prioridad manuales no comprometan la estabilidad del sistema.\n",
    "\n",
    "### **9. Impacto de las Prioridades en el Sistema Operativo**\n",
    "\n",
    "Rendimiento General:\n",
    "\n",
    "- Una gestión eficiente de las prioridades mejora el rendimiento general del sistema, asegurando que las tareas más importantes se ejecuten de manera oportuna.\n",
    "\n",
    "Responsividad:\n",
    "\n",
    "- Al dar mayor prioridad a las aplicaciones interactivas, el sistema operativo mejora la responsividad, proporcionando una experiencia de usuario más fluida.\n",
    "\n",
    "Eficiencia en el Uso de Recursos:\n",
    "\n",
    "- Permite una utilización más eficiente de los recursos del sistema, asignando tiempo de CPU y otros recursos de manera óptima según la importancia de las tareas.\n",
    "\n",
    "Estabilidad y Seguridad:\n",
    "\n",
    "- Al priorizar procesos críticos y gestionar adecuadamente las prioridades, el sistema operativo mantiene la estabilidad y evita que procesos defectuosos o maliciosos afecten negativamente al sistema.\n",
    "\n",
    "### **10. Consideraciones de Seguridad al Gestionar Prioridades**\n",
    "\n",
    "Permisos de Usuario:\n",
    "\n",
    "- Usuarios Estándar: Generalmente, tienen permisos limitados para cambiar las prioridades de sus propios procesos.\n",
    "\n",
    "- Administradores/Superusuarios: Pueden ajustar las prioridades de cualquier proceso en el sistema, lo que requiere un control adecuado para prevenir abusos.\n",
    "\n",
    "Prevención de Abusos:\n",
    "\n",
    "- Limitación de Prioridades Críticas: Restringir la asignación de prioridades extremadamente altas a procesos de usuario para evitar que monopolicen los recursos del sistema.\n",
    "\n",
    "- Políticas de Seguridad: Implementar políticas que controlen quién puede cambiar las prioridades y bajo qué condiciones.\n",
    "\n",
    "___\n",
    "\n",
    "## Scheduling\n",
    "\n",
    "### **Que es el scheduling?**\n",
    "\n",
    "El scheduling es el proceso mediante el cual el SO decide que proceso o hilo se ejecutara a continuacion en la CPU. Dado que la CPU es un recurso limitado, y multiples procesos y hilos compiten por el, la planificacion eficiente es esencial para asegurar un uso optimo de los recursos del sistema, mantener la responsividad y garantizar que las tareas criticas se completen a tiempo.\n",
    "\n",
    "### **Objetivos del Scheduling**\n",
    "\n",
    "Los principales objetivos de los algoritmos de scheduling incluyen:\n",
    "\n",
    "- Maxixmizar el rendimiento del sistema: Maximizar el uso de la CPU y minimizar el tiempo de inactividad.\n",
    "\n",
    "- Minimizar el tiempo de espera: Reducir el tiempo que los procesos pasan esperando para ser ejecutados.\n",
    "\n",
    "- Maximizar la responsividad: Asegurar que los procesos interactivos respondan rapidamente.\n",
    "\n",
    "- Equidad: Garantizar que todos los procesos tengan una oportunidad justa de ejecutarse.\n",
    "\n",
    "- Priorizar tareas criticas: Asegurar que las tareas importantes o criticas reciban los recursos necesarios.\n",
    "\n",
    "### **Desafios en la planificacion**\n",
    "\n",
    "- Starvation (Inanicion): Ocurre cuando ciertos procesos nunca reciben tiempo de CPU debido a que siempre hay otros procesos con mayor prioridad.\n",
    "\n",
    "- Equilibrio entre prioridad y equidad: Encontrar un balance entre dar prioridad a tareas importantes y asegurar que todas las tareas tengan una oportunidad de ejecutarse.\n",
    "\n",
    "- Context Switching: Cada cambio de contexto consume tiempo y recursos, por lo que minimizar estos cambios es crucial para mejorar el rendimiento.\n",
    "\n",
    "- Priority inversion: Situacion donde un proceso de baja prioridad mantiene un recurso necesario para un proceso de alta prioriad, bloqueando indirectamente al proceso de alta prioridad.\n",
    "\n",
    "### **Algoritmos de Scheduling**\n",
    "\n",
    "Existen multiples algoritmos de scheduling, cada uno con sus propias ventas y desventajas.\n",
    "\n",
    "**First-Come, First-Served (FCFS)**: Los procesos se ejecutan en el orden en que llegan.\n",
    "\n",
    "- Ventajas:\n",
    "    \n",
    "    - Simplicidad en la implementacion\n",
    "\n",
    "    - Justo en terminos de orden de llegada.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Tiempo de espera prolongado: Un procso largo puede retrasar a muchos procesos que llegan despues (problema del convoy)\n",
    "\n",
    "    - No considera prioridades: Todos los procesos tienen la misma prioridad.\n",
    "\n",
    "- Uso: Rara vez se usa en sistemas modernos debido a sus limitaciones en el manejo de la eficiencia y la responsividad\n",
    "\n",
    "**Shortes Job First (SJF)**: Selecciona el proceso con el menor tiempo de ejecucion esperado.\n",
    "\n",
    "- Ventajas:\n",
    "    \n",
    "    - Minimiza el tiempo promedio de espera.\n",
    "\n",
    "    - Mejor eficiencia en la utilizacion de la CPU.\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Starvation: Los procesos largos pueden nunca ejecutarse si continuamente llegan procesos mas cortos\n",
    "\n",
    "    - Estimacion del tiempo de ejecucion: Requieren una estimacion precisa del tiempo de ejecucion de los procesos.\n",
    "\n",
    "- Uso: Utilizado en entornos donde se puede predecir el tiempo de ejecucion de los procesos, aunque es raro en la practica.\n",
    "\n",
    "**Round Robin (RR)**: Asigna un timeslice fijo a cada porceso en una cola circular.\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Equidad: Todos los procesos reciben una oportunidad igual para ejecutarse\n",
    "\n",
    "    - Responsividad: Adecuado para sistemas interactivos\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Overhead del context switching: Un timeslcie muy puequeno puede aumentar el numero de cambios de contexto, reduciendo la eficiencia.\n",
    "\n",
    "    - Tiempo de esepra variable: Los procesos con tareas mas largas pueden experimentar tiempos de esepra mas largos.\n",
    "\n",
    "- Uso: Comun en sistemas operativos modernos para manejar la multitarea de manera eficiente y equitativa.\n",
    "\n",
    "**Priority Scheduling**: Asigna prioridades a los procesos y ejecuta los de mayor prioridad primero.\n",
    "\n",
    "- Ventajas: \n",
    "\n",
    "    - Control de recursos: Permite priorizar tareas criticas.\n",
    "\n",
    "    - Flexibilidad: Se puede combinar con otros algoritmos (por ejemplo round robin dentro de la misma prioridad.)\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Starvation: Los procesos de baja prioridad pueden nunca ejecutarse si siempre hay procesos de mayor prioridad.\n",
    "\n",
    "    - Asignacion de prioridades: Determinar las prioridades adecuadas puede ser complejo.\n",
    "\n",
    "- Uso: Amplia utilziacion en sistemas donde ciertas tareas necestian una ejecucion mas rapida, como ne sistemas embebidos o de tiempo real.\n",
    "\n",
    "**Highest response ratio next (HRRN)**: Asigna prioridades basadas en el ratio entre el tiempo de espera y el tiempo de ejecucion esperado\n",
    "\n",
    "- Ventajas:\n",
    "\n",
    "    - Minimiza el tiempo de espera promedio: Equilibra entre procesos cortos y largos\n",
    "\n",
    "    - Previene starvation: Aumenta la prioridad de los procesos que han estado esperando mucho tiempo\n",
    "\n",
    "- Desventajas:\n",
    "\n",
    "    - Complejidad: Requiere calculos dinamicos y actualizaciones frecuentes. \n",
    "\n",
    "- Uso: Menos comun, pero puede ser util en entornos donde se requiere un balance entre eficiencia y equidad.\n",
    "\n",
    "### **Priority Inversion**\n",
    "\n",
    "La inversion de prioridad ocurre cuando un proceso de alta prioridad necesita un recurso que esta siendo utilizado por un proceso de baja prioridad, pero no puede acceder al recruso hasta que el proceso de baja prioridad lo libere. Mientras tanto, otros procesos de prioridad media pueden monopolizar la CPU, bloqueando indirectamente al proceso de alta prioridad.\n",
    "\n",
    "**Soluciones a la priority inversion**\n",
    "\n",
    "1. Priority Inheritance: Cuando un proceso de alta prioridad esta bloqueado esperando un recurso que esta siendo utilizado por un proceso de baja prioridad, el proceso de baja prioridad hereda temporalmente la prioridad del proceso de alta prioridad.\n",
    "\n",
    "- Ventajas: Permite que el proceso de baja prioridad termine mas rapido y libere el recurso\n",
    "\n",
    "- Implementacion: Comun en sistemas operativos modernos como Linux y Windows\n",
    "\n",
    "2. Priority Ceiling Protocol: Cada recurso tiene una prioridad maxima. Cuando un proceso accede a un recruso, su prioridad se eleva al nivel de prioridad del recurso, evitando que otros proceso de prioridad intermedia interfieran.\n",
    "\n",
    "- Ventajas: Previene la inversion de prioridad al asegurar que no se puedan interrumpir los procesos que poseen recursos criticos.\n",
    "\n",
    "- Desventajas: Puede ser restrictivo y limitar la flexibilidad del sistema.\n",
    "\n",
    "3. No inversion of priority: Diseniar sistemas y aplicaciones de manera que los procesos de baja prioridad no bloqueen los recursos necesarios para los procesos de alta prioridad.\n",
    "\n",
    "- Ventajas: Elimina la posibilidad de inversion de prioridad.\n",
    "\n",
    "- Desventajas: Requiere una planificacion cuidadosa y un disenio robusto de las aplicaciones y el sistema.\n",
    "\n",
    "****\n",
    "___\n",
    "\n",
    "## Collaborative Multiprocessing/Multithreading\n",
    "\n",
    "El multiprocesamiento/multihilo colaborativo es un enfoque donde los procesos o hilos ceden voluntariamente el control de la CPU para permitir que otros procesos o hilos sean ejecutados. En este modelo, la responsabiliad de gestionar el tiempo de CPU recae en las propias tareas, las cuales deben colaborar para compartir equitativamente los recursos del sistema.\n",
    "\n",
    "### **Funcionamiento**:\n",
    "\n",
    "1. Ceder control: Cada proceso o hilo debe ceder explicitamente el control de la CPU en puntos especificos de su ejecucion. Esto se puede hacer llamando a una funcion como yield().\n",
    "\n",
    "2. Planificacion basada en cooperacion: El SO asume que los procesos colaboran y que ninugno monopoliza la CPU. No hay preemision; es decir, el SO no interrumpe un proceso para asignar tiempo a otro.\n",
    "\n",
    "3. Gestion manual de tiemposlices: Los hilos deben gestionar manualmente cuanto tiempo ejecutan antes de ceder el control, lo que puede llevar a desequilibrios si no se implementa correctamente.\n",
    "\n",
    "### **Contexto historico**\n",
    "\n",
    "El multiprocesamiento colaborativo no estaba ampliamente soportado por el hardware en sus inicios. Sistemas operativos antiguos como DOS y Windows 3.11 operaban en un entorno de single-threading y single-processing, donde:\n",
    "\n",
    "- DOS: Era un SO de una sola tarea que no soportaba multitarea real. Las tareas parecian ejecutarse simultaneamente, pero en realidad se ejecutaban de manera secuencial rapida, dando la ilusion de multitarea.\n",
    "\n",
    "- Windows 3.1.11: Aunque permitia abrir multiples ventanas y aplicaciones, todas se ejecutaban en un unico procesador y en un solo hilo de ejecucion. La multitarea era cooperativa, es decir, las aplicaciones debian ceder el control voluntariamente para permitri que otras se ejecutaran.\n",
    "\n",
    "### **Ventajas**\n",
    "\n",
    "- Menor Overhead del SO: Al no tener que gestionar interrupciones y cambios de contexto frecuentes, se reduce la carga sobre el SO.\n",
    "\n",
    "- Predecibilidad: Las tareas conocen cuando cederan el control, lo que puede simplificar la programacion de aplicaciones en ciertos contextos.\n",
    "\n",
    "\n",
    "### **Desventajas**\n",
    "\n",
    "- Riesgo de Monopolizacion: Un proceso que no cede el control puede bloquear completamente el sistema, ya que el SO no puede intervenir.\n",
    "\n",
    "- Dificultad en la sincronizacion: Requiere que las tareas esten diseniadas cuidadosamente para cooperar, aumentando la complejidad de desarrollo.\n",
    "\n",
    "- Inanicion de procesos: Procesos de baja prioridad pueden quedar indefinidamente bloqueados si las tareas de alta prioridad nunca ceden el control.\n",
    "\n",
    "___\n",
    "\n",
    "## Preemptive Multiprocessing/Multithreading\n",
    "\n",
    "El mulitprocesamiento/multihilo preventivo es un enfoque donde el SO controla de manera activa la asignacion de tiempo de CPU a los procesos y hilos. el SO puede interrumpir una tarrea en ejecucion para asignar tiempo a otra, basandose en prioridades, politicas de planificacion y la necesidad de mantener la equidad y la eficiencia del sistema.\n",
    "\n",
    "### **Funcionamiento**\n",
    "\n",
    "1. Interrupciones del SO: El SO puede interrumpir cualquier proceso o hilo en ejecucion despues de un determinado timeslice para asignar tiempo a otro proceso.\n",
    "\n",
    "2. Planificacion basada en prioridades: El SO puede asignar mayores tiempos de CPU a procesos de alta prioridad y menores tiempos a los de baja prioridad.\n",
    "\n",
    "3. Preemision: El SO tiene la autoridad para cambiar de contexto sin la cooperacion de los procesos o hilos, asegurando que todas las tareas tengan la oportunidad de ejecutarse.\n",
    "\n",
    "### **Contexto historico**\n",
    "\n",
    "Con la evolucion del hardware y la necesidad de sistemas mas responsivos y eficientes, el multiprocesamiento/multihilo preventivo se convirtio en el estandar en SO modernos como Windows NT, Linux, macOS, y otros. Estos sistemas aprovechan las capacdiaddes de los procesadores multinuecleo y la necesidad de ejecutar multiples tareas simultaneamente sin depender de la cooperacion de las aplicaciones.\n",
    "\n",
    "### **Ventajas**\n",
    "\n",
    "- Equidad y Responsividad: Asegura que todos los procesos reciban tiempo de CPU y que las tareas críticas respondan rápidamente.\n",
    "\n",
    "- Prevención de Monopolización: Un proceso no puede bloquear el sistema al no ceder el control, ya que el SO puede intervenir.\n",
    "\n",
    "- Mejor Utilización de Recursos: Optimiza el uso de la CPU distribuyendo equitativamente el tiempo entre múltiples procesos y hilos.\n",
    "\n",
    "### **Desventajas**\n",
    "\n",
    "- Overhead del Sistema Operativo: Los cambios de contexto frecuentes pueden consumir recursos y reducir el rendimiento general.\n",
    "\n",
    "- Complejidad en la Implementación: Requiere algoritmos de planificación más sofisticados y mecanismos de sincronización para gestionar las prioridades y evitar problemas como la inversión de prioridades.\n",
    "\n",
    "__\n",
    "\n",
    "## Transición Histórica hacia el Multiprocesamiento/Multihilo Preventivo\n",
    "\n",
    "Los sistemas operativos han evolucionado desde enfoques colaborativos hacia preventivos por varias razones:\n",
    "\n",
    "1. Incremento de la Complejidad de las Aplicaciones: Las aplicaciones modernas realizan múltiples tareas concurrentes que requieren una gestión eficiente de los recursos sin depender de la cooperación de las tareas.\n",
    "\n",
    "2. Mejora del Hardware: Con la llegada de procesadores multinúcleo y más potentes, se volvió esencial tener un sistema operativo capaz de gestionar múltiples procesos y hilos de manera eficiente.\n",
    "\n",
    "3. Necesidad de Responsividad y Estabilidad: Los sistemas preventivos aseguran que las aplicaciones críticas siempre tengan acceso a la CPU, mejorando la experiencia del usuario y la estabilidad del sistema.\n",
    "\n",
    "4. Seguridad: Evitan que aplicaciones mal diseñadas o defectuosas bloqueen el sistema, proporcionando una mejor protección contra fallos y comportamientos erráticos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
