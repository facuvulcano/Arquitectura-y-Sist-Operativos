{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs\n",
    "\n",
    "El avance de la inteligencia artificial, sobre todo el manejo de big data el uso de las GPUs ha sido muy importante para el crecimiento de este sector. Porque es mejor la GPU que la CPU? algunas similutdes y diferencias entre los dos tipos de procesador: La CPU son de proposito general, tienen un monton de instrucciones que sirven para hacer cualquier programa, no estan pensados para una aplicacion en especifica, al contrario, la GPU esta pensada absolutamente para especializarse en un conjunto muy chiquito de cosas que saben hacer muy rapido, pero que no saben hacer otra cosa. No se les puede pedir mas que eso, escencialmente una GPU calcula tanto numeros de puntos flotantes, como esta proyectado, como lo veria el observador, que sombras tendria, etc. Para eso es que fue diseniado. Las simiuitudes son: Los dos tienen la misma arquitectura de Von Neumann, los dos tienen una unidad de proceso, un procesador, RAM, y algunos dispositivos de entrada y salida (para el caso de GPU es muy limitado porque practicamente el dispositivo de salida es el monitor + una interfaz con la CPU para recibir los comandos de que quiero dibujar). Ahora, como normalmente dibujar un objeto en la pantalla se basa en una operacion matematica, obviamente uno hace lo mismo para un monton de vertices, entonces las GPUs tienen muchisimos mas cores que las CPUs pero son cores muchos mas simples, tiene pocas instrucciones muy enfocadas a lo que van a hacer pero tienen muchos cores. ma similitudes, los registros del procesador sirven como un registro grande pero tambien se pueden partir y hacer una operacion simultaneamente. Si tengo que rotrotasladar tengo que hacer un monton de productos y un monton de sumas, si cargo 4 vertices a la vez en un registro, agarro otros 4 y multiplico cada cuarto por su cuarto eso me da una ventaja de velocidad, las GPUs estan orientadas a eso, y eso es precisamente porque sirve en IA. Si tenemos un procesamiento de big data tenemos un monton de cosas sobre las cuales aplican las mismas formulas. Las GPUs suelen tener memorias mas rapidas que las CPUs, eso no es una ventaja en si misma porque las CPUs tienen mas memoria que las GPUs, entonces las GPUs tienen menos memoria y por ende suele ser mas rapida. Hoy en dia las maquinas usan DDR5 y las GPUs DDR6, estan un escalon mas arriba que las CPUs en velocidad. Las GPUs no acceden a la RAM de la computadora, hay procesadores que vienen con graficos integrados y esos procesadores comparten la misma memoria, que obviamente es mas lenta. Las CPUs estan muy documentadas, se puede acceder a todas las instrucciones, como operan sus bits, etc. Las GPUs como normalmente se inventaron para graficar y los drivers de esa GPU lo suele hacer la propia empresa que fabrico el hardware no hay mucha documentacion de como esta estructurada. Por ultimo las CPUs estan pensadas para una interfaz directa con el usuario mientras que las GPUs no, estan penadas para que otro preocesador le envie comandos de que tienen que graficar y ellas los grafican.\n",
    "\n",
    "## Interfaz con la CPU\n",
    "\n",
    "Al no tener interfaz con el usuario la unica forma de comunicarse con esa placa es que esa placa represente un conjunto de direcciones dentro del espacio de memoria del procesador principal, a traves de las cuales el procesador principal le puede enviar comandos para que la GPU haga. Sin embargo, no esta muy documentado como funciona eso, de la misma forma que compro un disco que tiene un chip con ciertas direcciones de memoria y el fabricante le hace el driver, aca yo compro la placa de video que tambien tiene un chip que tiene ciertos comandos y el fabricante me hace el driver, la realidad es que no es muy necesario que yo sepa como se intercambia informacion entre la GPU y la CPU, o por lo menos no era si. Ahora, cuando la gente empiece a usar las GPUs para otra cosa ahi empieza a cambiar. Estos drivers, la idea es que tengan interfaces de mas alto nivel para que las aplicaciones puedan dibujar cosas, proyectar o que se muevan sin necesidad de conocer el protocolo especifico. Los protocolos mas comunes que son los que expone el SO y que implementa a traves de estos drivers son: el OpenGL, arquitectura abierta que fue de las primeras que hubo, ya no esta mantenida, se dejo de mantener en el 2017, uno podia definir un objeto a traves de sus coordenadas un punto de vista de un observador y el OpenGL lo que permite es encontrar la proyeccion de ese objeto tridimencional tal como se veia desde determinada direccion, e inclusive se puede especificar un segundo vector que tiene la direccion de la luz. OpenGL se uso hasta hace poco incluso algunos siguen usandolo, la diferencia es que ya no es mantenido es decir no se le agregan cosas nuevas. Vulkan lo sucedio, tambien es de arquitectura abierta (la misma interfaz la tienen casi todos los SOs), entonces sucedio al OpenGL y es el sucesor hasta hoy, es decir es un producto mantenido. Direct3D lo saco micorosoft en 1995 y lo viene manteniendo hasta ahora, se pueden hacer cosas similares a los otros, en estos casos se apunta a poder definir objetos en el espacio pero las funciones y la interaz es otra. CUDA es algo que empezo despues, el CUDA nace porque la gente empieza a no querer usar las placas de video para video sino que para otras cosa, sea procesar grandes volumenes de datos, minar criptomonedas, etc.., en definitiva son un conjunto de operaciones matematicas no muy complejas pero que hay que hacerlas por montones para poder terminar a tiempo. CUDA la saca NVIDIA, hoy en dia hay dos grandes proovedores de placa de video AMD Y NVIDIA, CUDA lo saca NVIDIA en 2007 y de alguna forma lo que permite es escribir codigo pseudo C o pseudo fortran que en vez de ejecutar en la CPU va a ejecutar en la GPU, entonces el CUDA nace como una necesidad cuando la gente quiere empezar a usar las placas de video no para video. AMD respondio y saca ZLUDA, que es parecido a CUDA y permite hacerlo en las placas de AMD. De todas formas todo lo que es procesamiento suele usar CUDA hoy en dia.\n",
    "\n",
    "## Forma de graficar\n",
    "\n",
    "Como funcionan? La forma mas rapida de definir objetos en el espacio es dividir su superficie en poligonos, generalmente por simplicidad triangulos y a lo sumo cuadrilateros. Se puede aplicar bastante matematica dado que el error de los triangulos para representar superficies es bastante bajo. Escencialmente dependiendo de como me convenga, puedo definir a los triangulos de distintas formas, una es como triangulos independientes, le tengo que pasar 3 vertices a cada uno. Esto no se suele hacer porque cuando quiero representar un cuerpo en el espacio y divido en triangulos, esos triangulos se tocan los lados entre si, entonces si los trato como triangulos independientes algunos vertices los voy a calcular dos veces, con lo cual muchas veces se utilizan tiras de triangulos en donde el primer vertice se especifica y luego se especifican dos por cada uno. Entonces siempre ire agregando un vertice mas, armo el primer triangulo y voy armando los demas triangulos agregando solo un vertice lo que en consecuencia optimiza el trabajo. Estas tecnicas apuntan a no hacer trabajo duplicado Otra alternativa es utilizar un abanico de triangulos. Cuando una aplicacion quiere dibujar lo que hace es utilizar un conjunto de estos metodos. La GPU no solamente permite tomar el objeto como si fuese un monton de lineas en el espacio y proyectarlas sino que puedo darle un color en cada extremo y que la GPU encuentre todas las texturas intermedias para que eso se vea bien. En principio le defino el cuerpo y luego las texturas y los colores. \n",
    "\n",
    "## Capacidad de multiprocesamiento\n",
    "\n",
    "Para realmente poder hacer esto rapido, los cores que tiene la GPU no son todos iguales, hay algunos que estan pensados para hacer una tarea y otros estan pensados para hacer otras. Son fisicamente distintos tienen hardware distinto que les permite hacer la tarea que puede hacer mas rapido y no puede hacer las otras. Las GPUs hoy en dia tienen 3 tipos de cores. Los que se llaman nucelos CUDA que estan destinados a generar texturas en los poliedros. Uno define un poliedro y esos cores estan especificamente pensados para detectar y armar la textura entre cada uno de esos triangulos, cuadrados, etc. Los nucleos de tensores son los que hacen las rototraslaciones, no solo determinan como se ve sino que tambien si se ve o no. Finalmente hay un conjunto de nucelos que se llama RT o ray tracing o rastreo de rayos que escencialmnete estan orientados especificamente a calcular la interseccion entre una linea y un objeto, donde esa linea intersecta con un determinado objeto. Pensado especialmente para los disparos en juegos. Para tener una idea de dimensionamiento, una placa hoy en dia GeForce RTX 4090 es una placa del orden de 1500 dolares. Esta placaa tiene 16384 CUDA cores (un intel core i9 4900k de USD 800 tiene 24), esta placa tambien tiene 512 tensor cores, y 128 RT cores. Esta placa en particular es relativamente buena hoy en dia. Lo que se quiere mostrar es cuando hablamos de procesadores de CPUs hablamos de decenas de cores mientras que cuando hablamos de GPUs hablamos de decenas de miles. Por supuesto hay un monton de operaciones que las GPUs no tienen pero no estan pensadas para eso. En circustancias normales todo esto trabaja con un piplening, primero hay que usar los nucleos tensores para rototrasladar los triangulos y ver cuales y como va a ver el punto de vista del observador. Despues, habra que utilizar los nucleos de CUDA para calcular la textura, el brillo, reflejo de cada uno de esos triangulos, y finalmente opcionalmente, si hay disparos o algo se usaran los nucleos RT.\n",
    "\n",
    "## Ray Tracing\n",
    "\n",
    "Hay dos tareas que son enrealidad matematicamente las mismas, por un lado los nucelos RT calculaban la interseccion entre una recta y algun objeto de todos los que estaban definidos en ese espacio tridimensional, ahora el mismo algoritmo que podemos usar para encontrar el punto de impacto de un proyectil lo podemos utilizar para determinar una sombra, porque en definitiva, si tomara un rayo que nace de la fuente de luz y pasa por el borde del objeto, quiero ver donde se termina impactando contra algun otro objeto ese lugar es donde tengo que dibujar la sombra, entonces los mismos cores RT tambien se usan para la proyeccion de sombras en la pantalla. Ahora bien, la idea de estos equipos es hacer esas tareas sencillas de la forma mas rapida posible. Para hacerlas de la forma mas rapida posible hay dos alternativas, la obvia es aumentar la velocidad de calculo, es decir pongo una CPU mas rapida, memoria mas rapida etc, entonces voy a hacer las cuentas mas rapido. Y la otra alternativa es reducir la complejidad del problema cosa que se usa mucho en las aplicaciones graficas. En facil, si estoy mirando para adelante porque calcularia las sombras que estan detras mio. Para aumentar la velocidad, dos alternativas nada mas. Como mayor ingenio, encontrar algoritmos matematicos que permitan hacer lo mismo de una forma mas sencilla, o la obvia de tener hardware mas rapido. Hoy en dia no es el punto principal de avance de tecnologia. Hoy en dia las grandes mejoras se estan dando por la reduccion de complejidad, en otras palabras no hacer calculos a lo bruto de todo sino que tratar de alguna forma de poder primero decir que tengo que calcular. Una alternativa para reducir es utilizar volumenens contenedores: La GPU determina primero el poliedro que contiene un grupo de elementos. Si no hay interseccion con este, no puede haber interseccion con ninguno de los contenedores. Otra alternativa para reducir es la division espacial: se divide el espacio en secciones, a veces iguales y a veces no y se calcula si el rayo va a atravesar esa seccion o no. Si el rayo no va a travesar esa seccion descarto todo lo que esta ahi. Despues hay mas complejos que son tecnicas direccionales: se parte de un cubo centrado en el orgien del rayo. Primero se calcula la posicion (cara y coordenadas) sobre las que pasa el rayo. Luego se proyectan todos los objetos sobre las caras del cubo. Una vez hecho esto se busca la interseccion del rayo solo con los objetos que estan en la cara de impacto. Todo esto no viene con la GPU sino con el ingenio del programador. \n",
    "\n",
    "## CUDA\n",
    "\n",
    "CUDA esta pensado especificamente para SIMD. Se define una funcion que lleva a cabo una operacion matematica y se quiere que esta operacion matematica se lleve a cabo sobre un gran conjunto de datos, es un pseudo C porque cuando uno declara una funcion la puede declarar como una funcion unica pero lo mas comun es encontarla con otro formato. GridSize es una matriz tridimencional que determina los grados de libertad que da la placa para la ejecucion, podria ejecutar los datos sobre una matriz tridimencional de valores. Ademas se le puede especificar un BLockSize, esto es cuantas de estas funciones se pueden ejecutar en paralelo. En principio uno diria todas las que pueda, pero no siempre es asi. Entonces se definen las funciones de esta forma: Funcion<<<GridSize, BlockSize>>>(); Se programa en una especie de pseudo C en el cual uno puede ver una serie de variables globales que son las que nos intersan. En principio la dimension del bloque: blocDim: Cantidad de threads en cada bloque. La dimension de la matriz: gridDim: Dimensiones de la matriz GridSize con que se lanzo el kernel. Numero de bloque que represento yo: blockkIdx y numero de thread dentro del bloque: threadIdx. Hay que tener en cuenta que los cores de la GPU no ven la memoria principal de la CPU, por lo tanto todos los datos que se requieeren para calcular se deben colocar en un buffer de intercambio entre procesadores. Por lo general ese buffer tiene un conjunto de matrices. La funcion kernel utiliza las variables globales descritas para determinar que elemento le toca procesar. Levanta los datos de las matrices y coloca los resultados en otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
